{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D_Input(filters, kernel_size, strides, padding, activation, kernel_regularizer, name, input_shape):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name, \n",
    "                                  input_shape = input_shape)\n",
    "\n",
    "\n",
    "def Conv2D(filters, kernel_size, strides, padding, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name)\n",
    "\n",
    "def MaxPool(pool_size, strides, padding, name):\n",
    "    return tf.keras.layers.MaxPooling2D(pool_size = pool_size, strides = strides, \n",
    "                                        padding = padding, name = name)\n",
    "\n",
    "def Flatten(name):\n",
    "    return tf.keras.layers.Flatten(name = name)\n",
    "\n",
    "def Dense(units, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Dense(units = units, activation = activation, \n",
    "                                 kernel_regularizer=kernel_regularizer,name = name)\n",
    "\n",
    "def Batch_Normalize():\n",
    "    return tf.keras.layers.BatchNormalization(axis= -1)\n",
    "\n",
    "def DropOut(dropout_rate):\n",
    "    return tf.keras.layers.Dropout(dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(es_patience):\n",
    "    callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=es_patience,\n",
    "                                                               verbose=1, restore_best_weights=True)\n",
    "    callback_model= ModelCheckpoint(filepath='/home/ubuntu/kaggle/flowers/xray_images/Outputs/Best_Model', \n",
    "                                    save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [callback_early_stopping] #, callback_model]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run_model(Model, Opt_Algo, LR, Mtm, Loss, Metrics):\n",
    "    \n",
    "    if Opt_Algo == 'sgd':\n",
    "        Optimizer = tf.keras.optimizers.SGD(LR, Mtm)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)\n",
    "    \n",
    "    elif Opt_Algo == 'adam':\n",
    "        Optimizer = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_data(train_dir, test_dir, batch_size, input_size):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(train_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size) \n",
    "    test_gen = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size)\n",
    "    \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(history, hyperparams, File_Name1, File_Name2):\n",
    "    \n",
    "    file = open(File_Name1,\"w\")\n",
    "    file.write(str(hyperparams))\n",
    "    file.close()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(history.history.items())\n",
    "    \n",
    "    df0 = pd.DataFrame()\n",
    "    for i in range(7):\n",
    "        df1 = pd.DataFrame(df[1][i],columns = [df[0][i]])\n",
    "        df0 = pd.concat([df0, df1], axis=1)\n",
    "    df0.to_csv(File_Name2)\n",
    "    \n",
    "    print(\"Model parameters and results have been exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(param_values, train_dir, test_dir, early_stopping, epochs):\n",
    "    \n",
    "    hyperparams = set_hyperparameters(param_values)\n",
    "    Model = generate_model(hyperparams)\n",
    "    \n",
    "    Model.summary()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Batch_Size: \"+str(hyperparams['BS']))\n",
    "    print(\"Learning_Rate: \"+str(hyperparams['LR']))\n",
    "    print(\"Momentum: \"+str(hyperparams['Mtm']))\n",
    "    print(\"Optimization_Algo: \"+str(hyperparams['Opt_Algo']))\n",
    "    print(\"Regularization_Cv_Layers\" + str(hyperparams['Cv_Reg']))\n",
    "    print(\"Regularization_Dense_Layers\" + str(hyperparams['Dl_Reg']))\n",
    "    print ()\n",
    "    print(\"\")\n",
    "\n",
    "    train_gen, test_gen = prepare_train_test_data(train_dir, test_dir, \n",
    "                                                  hyperparams['BS'], hyperparams['Input_Shape_WO_Channel'])\n",
    "    \n",
    "    compile_and_run_model(Model, hyperparams['Opt_Algo'], hyperparams['LR'], \n",
    "                          hyperparams['Mtm'], hyperparams['Loss'], \n",
    "                          hyperparams['Metrics'])\n",
    "    \n",
    "    callbacks = prepare_callbacks(hyperparams['Early_Stopping'])\n",
    "    \n",
    "    history = Model.fit(train_gen, validation_data= test_gen,\n",
    "                        epochs = hyperparams['Epochs'], verbose=1, callbacks = callbacks)\n",
    "    \n",
    "    File_Name1 = 'Hyperparams_Model_Evaluation.txt'\n",
    "    File_Name2 = 'Model_Results_Evaluation.csv'\n",
    "    \n",
    "    export_results(history, hyperparams, File_Name1, File_Name2)\n",
    "    return Model, history, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hyperparameters():\n",
    "    \n",
    "    LR = pow(10,-3.9)\n",
    "    Mtm = 0\n",
    "    BS = 64\n",
    "    \n",
    "    Cv_Bks = 3\n",
    "    Cv_CvLy = [2, 2, 1]\n",
    "    Cv_PoLy = [1, 1, 1]\n",
    "\n",
    "    Cv_Fil = [32, 64, 96]\n",
    "    Cv_KS =  add_for_each_block(3,Cv_Bks)\n",
    "    Cv_Reg = add_for_each_block(None,Cv_Bks)\n",
    "    Cv_Pd =  add_for_each_block('same',Cv_Bks)\n",
    "    Cv_Sd =  add_for_each_block((1, 1),Cv_Bks)\n",
    "    Cv_Av =  add_for_each_block('relu',Cv_Bks)\n",
    "\n",
    "    Po_PS =  add_for_each_block((2, 2),Cv_Bks)\n",
    "    Po_Pd =  add_for_each_block('same',Cv_Bks)\n",
    "    Po_Sd =  add_for_each_block((2, 2),Cv_Bks) \n",
    "    \n",
    "    Dl_Num = 1\n",
    "    Dl_Unt = [128]\n",
    "    Dl_Reg = add_for_each_block(None,Dl_Num)\n",
    "    Dl_Av =  add_for_each_block('relu',Dl_Num) \n",
    "    \n",
    "    Bch_Norm = 'none'\n",
    " \n",
    "    Dpout = 'none'\n",
    "    Dp_Rate = 0.5\n",
    "    \n",
    "    Opt_Algo = 'adam'\n",
    "    \n",
    "    Input_Shape = (224, 224, 3)\n",
    "    Input_Shape_WO_Channel = (224, 224)\n",
    "    Epochs = 10\n",
    "    Early_Stopping = 5\n",
    "    \n",
    "    Loss = 'binary_crossentropy'\n",
    "    Metrics = ['accuracy', 'Precision', 'Recall']\n",
    "    \n",
    "    assert(Cv_Bks == len(Cv_CvLy))\n",
    "    assert(Cv_Bks == len(Cv_PoLy))\n",
    "    assert(Dl_Num == len(Dl_Unt))\n",
    "  \n",
    "    hyperparams = {'LR':LR, 'Mtm':Mtm, 'BS':BS,\n",
    "                    'Cv_Bks':Cv_Bks, 'Cv_CvLy':Cv_CvLy, 'Cv_PoLy':Cv_PoLy, \n",
    "                    'Cv_KS':Cv_KS, 'Cv_Reg':Cv_Reg, 'Cv_Fil':Cv_Fil, \n",
    "                    'Cv_Pd':Cv_Pd, 'Cv_Sd':Cv_Sd, 'Cv_Av':Cv_Av, \n",
    "                    'Po_PS':Po_PS, 'Po_Pd':Po_Pd, 'Po_Sd':Po_Sd,\n",
    "                    'Dl_Num':Dl_Num,'Dl_Unt':Dl_Unt, 'Dl_Reg':Dl_Reg, 'Dl_Av':Dl_Av, \n",
    "                    'Bch_Norm':Bch_Norm, 'Dpout':Dpout, 'Dp_Rate':Dp_Rate,\n",
    "                    'Opt_Algo':Opt_Algo, 'Input_Shape':Input_Shape, \n",
    "                    'Input_Shape_WO_Channel':Input_Shape_WO_Channel,\n",
    "                    'Epochs':Epochs, 'Early_Stopping':Early_Stopping,\n",
    "                    'Loss':Loss, 'Metrics':Metrics}\n",
    "    \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(hyperparams):\n",
    "    \n",
    "    Cv_Bks  = hyperparams['Cv_Bks']\n",
    "    Cv_CvLy = hyperparams['Cv_CvLy']\n",
    "    Cv_PoLy = hyperparams['Cv_PoLy']\n",
    "    \n",
    "    Cv_KS = hyperparams['Cv_KS']\n",
    "    Cv_Reg = hyperparams['Cv_Reg']\n",
    "    Cv_Fil = hyperparams['Cv_Fil']\n",
    "    Cv_Pd = hyperparams['Cv_Pd']\n",
    "    Cv_Sd = hyperparams['Cv_Sd']\n",
    "    Cv_Av = hyperparams['Cv_Av']\n",
    "    \n",
    "    Po_PS = hyperparams['Po_PS']\n",
    "    Po_Pd = hyperparams['Po_Pd']\n",
    "    Po_Sd = hyperparams['Po_Sd']\n",
    "    \n",
    "    Dl_Num = hyperparams['Dl_Num']\n",
    "    Dl_Unt = hyperparams['Dl_Unt']\n",
    "    Dl_Reg = hyperparams['Dl_Reg']\n",
    "    Dl_Av = hyperparams['Dl_Av']\n",
    "    \n",
    "    Bch_Norm = hyperparams['Bch_Norm']\n",
    "    \n",
    "    Dpout = hyperparams['Dpout']\n",
    "    Dp_Rate = hyperparams['Dp_Rate']\n",
    "    \n",
    "    Input_Shape = hyperparams['Input_Shape']\n",
    "    Input_Shape_WO_Channel = hyperparams['Input_Shape_WO_Channel']\n",
    "    \n",
    "    Epochs = hyperparams['Epochs']\n",
    "    Early_Stopping = hyperparams['Early_Stopping']\n",
    "    \n",
    "    Loss = hyperparams['Loss']\n",
    "    Metrics = hyperparams['Metrics']\n",
    "                            \n",
    "    Model = tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(Cv_Bks):\n",
    "\n",
    "        Cv_Bk_Name = 'Blk' + str(i+1)\n",
    "\n",
    "        for j in range(Cv_CvLy[i]):\n",
    "            if (i==0 and j==0):\n",
    "                \n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D_Input(Cv_Fil[i], Cv_KS[i],\n",
    "                                  Cv_Sd[i], Cv_Pd[i],\n",
    "                                  Cv_Av[i], Cv_Reg[i],                         \n",
    "                                  Ly_Name, Input_Shape)\n",
    "                Model.add(Ly)\n",
    "\n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "            else:\n",
    "     \n",
    "\n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D(Cv_Fil[i], Cv_KS[i],\n",
    "                            Cv_Sd[i], Cv_Pd[i],\n",
    "                            Cv_Av[i], Cv_Reg[i],                         \n",
    "                            Ly_Name)\n",
    "                Model.add(Ly)\n",
    "            \n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "        for k in range(Cv_PoLy[i]):\n",
    "\n",
    "            Ly_Name = Cv_Bk_Name + '_Pool' + str(k+1)\n",
    "            Ly = MaxPool(Po_PS[i], Po_Sd[i],\n",
    "                         Po_Pd[i], Ly_Name)\n",
    "            Model.add(Ly)\n",
    "        \n",
    "    Model.add(Flatten('Flatten'))\n",
    "\n",
    "    for l in range(Dl_Num):\n",
    "        \n",
    "        Ly_Name = 'Dense' + str(l+1)\n",
    "\n",
    "        Ly = Dense(Dl_Unt[l], Dl_Av[l], Dl_Reg[l], Ly_Name)\n",
    "        Model.add(Ly)\n",
    "\n",
    "        if Bch_Norm == 'dense' or Bch_Norm == 'all':\n",
    "            Ly = Batch_Normalize()\n",
    "            Model.add(Ly)\n",
    "\n",
    "        if Dpout == 'dense' or Dpout == 'all':\n",
    "            Ly = DropOut(Dp_Rate)\n",
    "            Model.add(Ly)\n",
    "\n",
    "    Model.add(Dense(1, 'sigmoid', None, 'Output'))\n",
    "    \n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/ubuntu/kaggle/data/xray_images/Data/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = set_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = generate_model(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, test_gen = prepare_train_test_data(train_dir, test_dir, \n",
    "                                              hyperparams['BS'], hyperparams['Input_Shape_WO_Channel'])\n",
    "    \n",
    "compile_and_run_model(Model, hyperparams['Opt_Algo'], hyperparams['LR'], \n",
    "                      hyperparams['Mtm'], hyperparams['Loss'], \n",
    "                          hyperparams['Metrics'])\n",
    "    \n",
    "callbacks = prepare_callbacks(hyperparams['Early_Stopping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 96)        55392     \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 75264)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               9633920   \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,755,009\n",
      "Trainable params: 9,755,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 82 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "82/82 [==============================] - 62s 751ms/step - loss: 0.3078 - accuracy: 0.8654 - Precision: 0.8699 - Recall: 0.9628 - val_loss: 0.6729 - val_accuracy: 0.7596 - val_Precision: 0.7239 - val_Recall: 0.9949\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 57s 698ms/step - loss: 0.1074 - accuracy: 0.9584 - Precision: 0.9711 - Recall: 0.9729 - val_loss: 1.0850 - val_accuracy: 0.7099 - val_Precision: 0.6837 - val_Recall: 0.9974\n",
      "Epoch 3/10\n",
      "18/82 [=====>........................] - ETA: 42s - loss: 0.0666 - accuracy: 0.9731 - Precision: 0.9813 - Recall: 0.9824"
     ]
    }
   ],
   "source": [
    "history = Model.fit(train_gen, validation_data= test_gen,\n",
    "                    epochs = hyperparams['Epochs'], verbose=1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model, history, hyperparams = run_model(param_values, train_dir, test_dir, 15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in Model.layers[0:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/home/ubuntu/kaggle/flowers/xray_images/Data/train/PNEUMONIA/'\n",
    "image_path = image_dir + 'person997_virus_1678.jpeg'\n",
    "\n",
    "\n",
    "# Loading the image and converting it to a numpy array for feeding it to the model. Its important to use expand_dims since our original model takes batches of images\n",
    "# as input, and here we are feeding a single image to it, so the number of dimensions should match for model input.\n",
    "img = image.load_img(image_path, target_size=(224, 224))\n",
    "img_arr = image.img_to_array(img)\n",
    "img_arr = np.expand_dims(img_arr, axis=0)\n",
    "img_arr /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = tf.keras.Model(inputs = Model.inputs, outputs = [layer.output for layer in Model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_arr)\n",
    "input_img = img_arr.reshape(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(1, 8, i + 1)\n",
    "    ax = plt.imshow(activations[0][0, :, :, i], cmap='inferno')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.imshow(activations[6][0, :, :,11], cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_dir = '/home/ubuntu/kaggle/flowers/xray_images/Data/test/PNEUMONIA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_fnames = os.listdir(test_normal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(test_normal_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    img_arr /= 255.\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_normal_dir + test_normal_fnames[0]\n",
    "model_input = get_image_array(image_path)\n",
    "model_output = Model.predict(model_input)\n",
    "model_output_all = model_output\n",
    "\n",
    "length = len(test_normal_fnames)\n",
    "\n",
    "for i in range(1,length):\n",
    "    image_path = test_normal_dir + test_normal_fnames[i]\n",
    "    model_input = get_image_array(image_path)\n",
    "    model_output = Model.predict(model_input)    \n",
    "    model_output_all = np.concatenate((model_output_all,model_output), axis = 0)\n",
    "    \n",
    "y_hat = model_output_all.reshape(length,1)\n",
    "image_path = np.array(test_normal_fnames).reshape(length,1)\n",
    "model_eval = np.concatenate((image_path,y_hat), axis=1)\n",
    "model_eval = pd.DataFrame(model_eval, columns=['Image_Path', 'Y_hat'])\n",
    "model_eval['Image_Path'] = test_normal_dir + model_eval['Image_Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval['Y_hat'] = model_eval['Y_hat'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_images = model_eval[model_eval['Y_hat']>0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = viz_images.iloc[4]['Image_Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = get_image_array(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = tf.keras.Model(inputs = Model.inputs, outputs = [layer.output for layer in Model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_arr)\n",
    "input_img = img_arr.reshape(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(1, 8, i + 1)\n",
    "    ax = plt.imshow(activations[4][0, :, :, i], cmap='inferno')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_arr.reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.get_layer('Blk1_Conv1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    \n",
    "    layer_output = Model.get_layer(layer_name).output\n",
    "    \n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    \n",
    "    grads = K.gradients(loss, complete_model.input)[0]\n",
    "    \n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    \n",
    "    iterate = K.function([complete_model.input], [loss, grads])\n",
    "    \n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "    \n",
    "    step = 1.\n",
    "    \n",
    "    for i in range(80):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    \n",
    "    img = input_img_data[0]\n",
    "    \n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 12))\n",
    "\n",
    "for img in range(30):\n",
    "    ax = fig.add_subplot(5, 6, img+1)\n",
    "    ax = plt.imshow(generate_pattern('conv2d_1', img))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
