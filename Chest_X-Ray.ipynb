{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/ankit/kaggle_comp/kaggle/chest_xray/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training images\n",
    "train_normal_dir = os.path.join(train_dir, 'NORMAL')\n",
    "train_pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_fnames = os.listdir(train_normal_dir)\n",
    "train_pneumonia_fnames = os.listdir(train_pneumonia_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training images\n",
    "val_normal_dir = os.path.join(val_dir, 'NORMAL')\n",
    "val_pneumonia_dir = os.path.join(val_dir, 'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_normal_fnames = os.listdir(val_normal_dir)\n",
    "val_pneumonia_fnames = os.listdir(val_pneumonia_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training images\n",
    "test_normal_dir = os.path.join(test_dir, 'NORMAL')\n",
    "test_pneumonia_dir = os.path.join(test_dir, 'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normal_fnames = os.listdir(test_normal_dir)\n",
    "test_pneumonia_fnames = os.listdir(test_pneumonia_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total  1341 Normal images in the 'Train' dataset.\n",
      "There are total  3875 Pneumonia images in the 'Train' dataset.\n",
      "There are total  8 Normal images in the 'Validation' dataset.\n",
      "There are total  8 Penumonia images in the 'Validation' dataset.\n",
      "There are total  233 Normal images in the 'Test' dataset.\n",
      "There are total  389 Penumonia images in the 'Test' dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are total \", len(train_normal_fnames) - 1, \"Normal images in the 'Train' dataset.\")\n",
    "print(\"There are total \", len(train_pneumonia_fnames) - 1, \"Pneumonia images in the 'Train' dataset.\")\n",
    "print(\"There are total \", len(val_normal_fnames) -1, \"Normal images in the 'Validation' dataset.\")\n",
    "print(\"There are total \", len(val_pneumonia_fnames) -1, \"Penumonia images in the 'Validation' dataset.\")\n",
    "print(\"There are total \", len(test_normal_fnames) -1, \"Normal images in the 'Test' dataset.\")\n",
    "print(\"There are total \", len(test_pneumonia_fnames) -1, \"Penumonia images in the 'Test' dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding = 'same', input_shape=(224, 224, 3)),\n",
    "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'), \n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,666,401\n",
      "Trainable params: 1,666,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=50,\n",
    "                                                    color_mode= 'rgb',\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(224, 224))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator =  val_datagen.flow_from_directory(val_dir,\n",
    "                                                 batch_size=50,\n",
    "                                                 color_mode= 'rgb',\n",
    "                                                 class_mode='binary',\n",
    "                                                 target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                 batch_size=50,\n",
    "                                                 color_mode= 'rgb',\n",
    "                                                 class_mode='binary',\n",
    "                                                 target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 190s 4s/step - loss: 0.5342 - accuracy: 0.7725 - val_loss: 0.9187 - val_accuracy: 0.7099\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 168s 3s/step - loss: 0.2980 - accuracy: 0.8812 - val_loss: 0.3686 - val_accuracy: 0.8510\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 188s 4s/step - loss: 0.2308 - accuracy: 0.9205 - val_loss: 0.8322 - val_accuracy: 0.7628\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 180s 4s/step - loss: 0.1485 - accuracy: 0.9424 - val_loss: 0.5443 - val_accuracy: 0.8237\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 170s 3s/step - loss: 0.0939 - accuracy: 0.9647 - val_loss: 1.0037 - val_accuracy: 0.7196\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 170s 3s/step - loss: 0.0962 - accuracy: 0.9676 - val_loss: 1.0235 - val_accuracy: 0.8029\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 178s 4s/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 1.2476 - val_accuracy: 0.7452\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 173s 3s/step - loss: 0.1007 - accuracy: 0.9708 - val_loss: 1.0998 - val_accuracy: 0.7933\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 173s 3s/step - loss: 0.0554 - accuracy: 0.9797 - val_loss: 1.5088 - val_accuracy: 0.7724\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9792"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=test_generator,\n",
    "                    steps_per_epoch=50,\n",
    "                    epochs=10,\n",
    "                    validation_steps=None,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('/home/ankit/kaggle_comp/kaggle/chest_xray/train/PNEUMONIA/person1002_bacteria_2933.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread('/home/ankit/kaggle_comp/kaggle/chest_xray/train/PNEUMONIA/person1002_bacteria_2933.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_normal_fnames:\n",
    "    img = mpimg.imread('/home/ankit/kaggle_comp/kaggle/chest_xray/train/NORMAL/' + tr)\n",
    "    size = img.shape\n",
    "    print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread('/home/ankit/kaggle_comp/kaggle/chest_xray/train/PNEUMONIA/person1002_bacteria_2933.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "pic_index+=8\n",
    "\n",
    "next_normal_pix = [os.path.join(train_normal_dir, fname) \n",
    "                for fname in train_normal_fnames[ pic_index-8:pic_index]]\n",
    "\n",
    "next_pneumonia_pix = [os.path.join(train_pneumonia_dir, fname) \n",
    "                for fname in train_pneumonia_fnames[ pic_index-8:pic_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_path in enumerate(next_normal_pix+next_penumonia_pix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_path in enumerate(next_normal_pix+next_penumonia_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
