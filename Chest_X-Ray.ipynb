{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/ankit/kaggle_comp/kaggle/chest_xray/Data/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HyperParameters:\n",
    "- Learning Rate \n",
    "- Momentum \n",
    "- Number of Conv Blocks\n",
    "- Number of Layers in Each Block \n",
    "- Parameters of each Layer (Conv, Pooling, Flatten, Dense)\n",
    "- Regularization \n",
    "- Batch Normalization \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D_Input(filters, kernel_size, strides, padding, activation, kernel_regularizer, name, input_shape):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name, \n",
    "                                  input_shape = input_shape)\n",
    "\n",
    "\n",
    "def Conv2D(filters, kernel_size, strides, padding, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name)\n",
    "\n",
    "def MaxPool(pool_size, strides, padding, name):\n",
    "    return tf.keras.layers.MaxPooling2D(pool_size = pool_size, strides = strides, \n",
    "                                        padding = padding, name = name)\n",
    "\n",
    "def Flatten(name):\n",
    "    return tf.keras.layers.Flatten(name = name)\n",
    "\n",
    "def Dense(units, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Dense(units = units, activation = activation, \n",
    "                                 kernel_regularizer=kernel_regularizer,name = name)\n",
    "\n",
    "def Batch_Normalize():\n",
    "    return tf.keras.layers.BatchNormalization(axis=1)\n",
    "\n",
    "def DropOut(dropout_rate):\n",
    "    return tf.keras.layers.Dropout(dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - To be convereted to functions before posting\n",
    "def set_hyperparameters(param):\n",
    "    \n",
    "    LR_10P_Range = param['LR_10P_Range'] \n",
    "    Mtm_Val = param['Mtm_Val'] \n",
    "    BS_Val = param['BS_Val']  \n",
    "    Cv_Bks_Val= param['Cv_Bks_Val']  \n",
    "    Cv_CvLy_Val= param['Cv_CvLy_Val']  \n",
    "    Cv_PoLy_Val = param['Cv_PoLy_Val'] \n",
    "    Cv_KS_Val = param['Cv_KS_Val']  \n",
    "    Cv_Reg_Val = param['Cv_Reg_Val']\n",
    "    Cv_Fil_Val = param['Cv_Fil_Val']  \n",
    "    Cv_Pd_Val = param['Cv_Pd_Val']  \n",
    "    Cv_Sd_Val = param['Cv_Sd_Val']  \n",
    "    Cv_Av_Val = param['Cv_Av_Val']  \n",
    "    Po_PS_Val = param['Po_PS_Val'] \n",
    "    Po_Pd_Val = param['Po_Pd_Val'] \n",
    "    Dl_Num_Val = param['Dl_Num_Val']  \n",
    "    Dl_Unt_Val = param['Dl_Unt_Val']  \n",
    "    Dl_Reg_Val = param['Dl_Reg_Val']  \n",
    "    Dl_Reg_Val = param['Dl_Reg_Val'] \n",
    "    Bch_Norm_Val = param['Bch_Norm_Val']  \n",
    "    Dpout_Val = param['Dpout_Val']  \n",
    "    Dp_Rate = param['Dp_Rate']\n",
    "    Opt_Algo_Val= param['Opt_Algo_Val']  \n",
    "    Input_Shape = param['Input_Shape']\n",
    "    \n",
    "\n",
    "    LR = pow(10,random.uniform(LR_10P_Range[0],LR_10P_Range[1]))\n",
    "    \n",
    "    random.shuffle(Mtm_Val)\n",
    "    Mtm = Mtm_Val[0]\n",
    "    \n",
    "    random.shuffle(BS_Val)\n",
    "    BS = BS_Val[0]\n",
    "    \n",
    "    random.shuffle(Cv_Bks_Val)\n",
    "    Cv_Bks = Cv_Bks_Val[0]\n",
    "    \n",
    "    Cv_CvLy = []\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "\n",
    "        random.shuffle(Cv_CvLy_Val)\n",
    "        Cv_CvLy.append(Cv_CvLy_Val[0])\n",
    "\n",
    "    Cv_KS = []\n",
    "    Cv_Reg = []\n",
    "    Po_PS = []\n",
    "    Po_Sd = []\n",
    "\n",
    "    random.shuffle(Cv_KS_Val)\n",
    "    random.shuffle(Cv_Reg_Val)\n",
    "    random.shuffle(Po_PS_Val)\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_KS.append(Cv_KS_Val[0])\n",
    "        Cv_Reg.append(Cv_Reg_Val[0])\n",
    "        Po_PS.append(Po_PS_Val[0])\n",
    "        Po_Sd.append(Po_PS_Val[0])\n",
    "    \n",
    "    Cv_Fil = []    \n",
    "    random.shuffle(Cv_Fil_Val)\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_Fil.append(Cv_Fil_Val[0]*pow(2,math.ceil((i+1)/2)-1))  \n",
    "        \n",
    "    Cv_Pd = []\n",
    "    Cv_Sd = []\n",
    "    Cv_Av = []\n",
    "    Cv_PoLy = []\n",
    "    Po_Pd = []\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_Pd.append(Cv_Pd_Val)\n",
    "        Cv_Sd.append(Cv_Sd_Val)\n",
    "        Cv_Av.append(Cv_Av_Val)\n",
    "        Cv_PoLy.append(Cv_PoLy_Val)\n",
    "        Po_Pd.append(Po_Pd_Val)\n",
    "    \n",
    "    random.shuffle(Dl_Num_Val)\n",
    "    Dl_Num = Dl_Num_Val[0]\n",
    "    \n",
    "    Dl_Unt =[]\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        random.shuffle(Dl_Unt_Val)\n",
    "        Dl_Unt.append(Dl_Unt_Val[0])\n",
    "        \n",
    "    Dl_Reg = []\n",
    "    random.shuffle(Dl_Reg_Val)\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        Dl_Reg.append(Dl_Reg_Val[0])\n",
    "    \n",
    "    Dl_Av = []\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        Dl_Av.append(Dl_Av_Val)\n",
    "\n",
    "    random.shuffle(Bch_Norm_Val)\n",
    "    Bch_Norm = Bch_Norm_Val[0]\n",
    "    \n",
    "    random.shuffle(Dpout_Val)\n",
    "    Dpout = Dpout_Val[0]\n",
    "    \n",
    "    random.shuffle(Opt_Algo_Val)\n",
    "    Opt_Algo = Opt_Algo_Val[0]\n",
    "    \n",
    "    hyperparams = {'LR':LR, 'Mtm':Mtm, 'BS':BS,\n",
    "                    'Cv_Bks':Cv_Bks, 'Cv_CvLy':Cv_CvLy, 'Cv_PoLy':Cv_PoLy, \n",
    "                    'Cv_KS':Cv_KS, 'Cv_Reg':Cv_Reg, 'Cv_Fil':Cv_Fil, \n",
    "                    'Cv_Pd':Cv_Pd, 'Cv_Sd':Cv_Sd, 'Cv_Av':Cv_Av, \n",
    "                    'Po_PS':Po_PS, 'Po_Pd':Po_Pd, 'Po_Sd':Po_Sd,\n",
    "                    'Dl_Num':Dl_Num,'Dl_Unt':Dl_Unt, 'Dl_Reg':Dl_Reg, 'Dl_Av':Dl_Av, \n",
    "                    'Bch_Norm':Bch_Norm, 'Dpout':Dpout, 'Dp_Rate':Dp_Rate,\n",
    "                    'Opt_Algo':Opt_Algo, 'Input_Shape':Input_Shape}\n",
    "    \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(hyperparams):\n",
    "    \n",
    "    Cv_Bks  = hyperparams['Cv_Bks']\n",
    "    Cv_CvLy = hyperparams['Cv_CvLy']\n",
    "    Cv_PoLy = hyperparams['Cv_PoLy']\n",
    "    Cv_KS = hyperparams['Cv_KS']\n",
    "    Cv_Reg = hyperparams['Cv_Reg']\n",
    "    Cv_Fil = hyperparams['Cv_Fil']\n",
    "    Cv_Pd = hyperparams['Cv_Pd']\n",
    "    Cv_Sd = hyperparams['Cv_Sd']\n",
    "    Cv_Av = hyperparams['Cv_Av']\n",
    "    Po_PS = hyperparams['Po_PS']\n",
    "    Po_Pd = hyperparams['Po_Pd']\n",
    "    Po_Sd = hyperparams['Po_Sd']\n",
    "    Dl_Num = hyperparams['Dl_Num']\n",
    "    Dl_Unt = hyperparams['Dl_Unt']\n",
    "    Dl_Reg = hyperparams['Dl_Reg']\n",
    "    Dl_Av = hyperparams['Dl_Av']\n",
    "    Bch_Norm = hyperparams['Bch_Norm']\n",
    "    Dpout = hyperparams['Dpout']\n",
    "    Dp_Rate = hyperparams['Dp_Rate']\n",
    "    \n",
    "    Model = tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(Cv_Bks):\n",
    "\n",
    "        Cv_Bk_Name = 'Blk' + str(i+1)\n",
    "\n",
    "        for j in range(Cv_CvLy[i]):\n",
    "            if (i==0 and j==0):\n",
    "                \n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D_Input(Cv_Fil[i], Cv_KS[i],\n",
    "                                  Cv_Sd[i], Cv_Pd[i],\n",
    "                                  Cv_Av[i], Cv_Reg[i],                         \n",
    "                                  Ly_Name, Input_Shape)\n",
    "                Model.add(Ly)\n",
    "\n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "            else:\n",
    "     \n",
    "\n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D(Cv_Fil[i], Cv_KS[i],\n",
    "                            Cv_Sd[i], Cv_Pd[i],\n",
    "                            Cv_Av[i], Cv_Reg[i],                         \n",
    "                            Ly_Name)\n",
    "                Model.add(Ly)\n",
    "            \n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "        for k in range(Cv_PoLy[i]):\n",
    "\n",
    "            Ly_Name = Cv_Bk_Name + '_Pool' + str(k+1)\n",
    "            Ly = MaxPool(Po_PS[i], Po_Sd[i],\n",
    "                         Po_Pd[i], Ly_Name)\n",
    "            Model.add(Ly)\n",
    "        \n",
    "    Model.add(Flatten('Flatten'))\n",
    "\n",
    "    for l in range(Dl_Num):\n",
    "        \n",
    "        Ly_Name = 'Dense' + str(l+1)\n",
    "\n",
    "        Ly = Dense(Dl_Unt[l], Dl_Av[l], Dl_Reg[l], Ly_Name)\n",
    "        Model.add(Ly)\n",
    "\n",
    "        if Bch_Norm == 'dense' or Bch_Norm == 'all':\n",
    "            Ly = Batch_Normalize()\n",
    "            Model.add(Ly)\n",
    "\n",
    "        if Dpout == 'dense' or Dpout == 'all':\n",
    "            Ly = DropOut(Dp_Rate)\n",
    "            Model.add(Ly)\n",
    "\n",
    "    Model.add(Dense(1, 'sigmoid', None, 'Output'))\n",
    "    \n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(es_patience):\n",
    "    callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=es_patience,\n",
    "                                                               verbose=1, restore_best_weights=True)\n",
    "    callback_model= ModelCheckpoint(filepath='Model_Best', save_best_only=True, \n",
    "                                    save_weights_only=True)\n",
    "    callbacks = [callback_early_stopping, callback_model]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run_model(Model, Opt_Algo, LR, Mtm, Loss, Metrics):\n",
    "    \n",
    "    if Opt_Algo == 'sgd':\n",
    "        Optimizer = tf.keras.optimizers.SGD(LR, Mtm)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)\n",
    "    \n",
    "    elif Opt_Algo == 'adam':\n",
    "        Optimizer = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_data(train_dir, test_dir, batch_size, input_size):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(train_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size) \n",
    "    test_gen = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size)\n",
    "    \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape = (224,224,3) \n",
    "Input_Shape_WO_Channel = (224,224) \n",
    "Loss = 'binary_crossentropy'\n",
    "Metrics = ['accuracy','Precision','Recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = tf.keras.regularizers.l2(0.005)\n",
    "Dp_Rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_10P_Range = [-4,-2] # Learning Rate \n",
    "Mtm_Val = [0.9,0] # Momentum \n",
    "BS_Val = [16,32,64,128] # Batch Size\n",
    "\n",
    "Cv_Bks_Val = [3,4,5] # Number of Conv Blocks\n",
    "Cv_CvLy_Val = [1,2] # Num of Conv Layers by Conv Blocks (Can be different in each Conv Block)\n",
    "Cv_PoLy_Val = 1 # Num of Pooling layers by Conv Blocks (Same by each Conv Block)\n",
    "\n",
    "Cv_KS_Val = [3,5] # Kernerl Size in Conv Layers by Conv Blocks (Same across all Conv Blocks) \n",
    "Cv_Reg_Val = [None, L2] # Regularizaion Type in Conv Layers by Conv Blocks (Same across all Conv Blocks)\n",
    "Cv_Fil_Val = [16,32,64] # Number of Filters in Conv Layers by Conv Blocks (This fixes the first, rest are followed a-a-2a-2a-4a)\n",
    "Cv_Pd_Val = 'same'\n",
    "Cv_Sd_Val = (1,1)\n",
    "Cv_Av_Val = 'relu'\n",
    "\n",
    "Po_PS_Val = [(2,2),(3,3)] # Pool Size in Pool Layers by Conv Blocks \n",
    "Po_Pd_Val = 'same'\n",
    "\n",
    "Dl_Num_Val = [1,2,3]\n",
    "Dl_Unt_Val = [128,256,512]\n",
    "Dl_Reg_Val = [None, L2]\n",
    "Dl_Av_Val = 'relu'\n",
    "\n",
    "Bch_Norm_Val = ['all','conv','dense','none']\n",
    "Dpout_Val = ['all','conv','dense','none']\n",
    "Opt_Algo_Val = ['sgd','adam']\n",
    "\n",
    "param_values = {'LR_10P_Range':LR_10P_Range, 'Mtm_Val':Mtm_Val, 'BS_Val':BS_Val,\n",
    "                'Cv_Bks_Val':Cv_Bks_Val, 'Cv_CvLy_Val':Cv_CvLy_Val, 'Cv_PoLy_Val':Cv_PoLy_Val, \n",
    "                'Cv_KS_Val':Cv_KS_Val, 'Cv_Reg_Val':Cv_Reg_Val, \n",
    "                'Cv_Fil_Val':Cv_Fil_Val, 'Cv_Pd_Val':Cv_Pd_Val, \n",
    "                'Cv_Sd_Val':Cv_Sd_Val, 'Cv_Av_Val':Cv_Av_Val, \n",
    "                'Po_PS_Val':Po_PS_Val, 'Po_Pd_Val':Po_Pd_Val, \n",
    "                'Dl_Num_Val':Dl_Num_Val, 'Dl_Unt_Val':Dl_Unt_Val,\n",
    "                'Dl_Reg_Val':Dl_Reg_Val, 'Dl_Av_Val':Dl_Av_Val, \n",
    "                'Bch_Norm_Val':Bch_Norm_Val, 'Dpout_Val':Dpout_Val,\n",
    "                'Dp_Rate':Dp_Rate, 'Opt_Algo_Val':Opt_Algo_Val,\n",
    "                'Input_Shape':Input_Shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = set_hyperparameters(param_values)\n",
    "Model = generate_model(hyperparams)\n",
    "Model.summary()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Batch_Size: \"+str(hyperparams['BS']))\n",
    "print(\"Learning_Rate: \"+str(hyperparams['LR']))\n",
    "print(\"Momentum: \"+str(hyperparams['Mtm']))\n",
    "print(\"Optimization_Algo: \"+str(hyperparams['Opt_Algo']))\n",
    "print(\"\")\n",
    "\n",
    "train_gen, test_gen = prepare_train_test_data(train_dir, test_dir, \n",
    "                                              hyperparams['BS'], Input_Shape_WO_Channel)\n",
    "compile_and_run_model(Model, hyperparams['Opt_Algo'], hyperparams['LR'], hyperparams['Mtm'],\n",
    "                      Loss, Metrics)\n",
    "callbacks = prepare_callbacks(10)\n",
    "history = Model.fit(train_gen, validation_data= test_gen,\n",
    "                    epochs=10, verbose=1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
