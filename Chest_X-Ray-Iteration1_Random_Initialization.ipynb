{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/ubuntu/kaggle/flowers/xray_images/Data/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHyperParameters:\\n- Learning Rate \\n- Momentum \\n- Number of Conv Blocks\\n- Number of Layers in Each Block \\n- Parameters of each Layer (Conv, Pooling, Flatten, Dense)\\n- Regularization \\n- Batch Normalization \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "HyperParameters:\n",
    "- Learning Rate \n",
    "- Momentum \n",
    "- Number of Conv Blocks\n",
    "- Number of Layers in Each Block \n",
    "- Parameters of each Layer (Conv, Pooling, Flatten, Dense)\n",
    "- Regularization \n",
    "- Batch Normalization \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D_Input(filters, kernel_size, strides, padding, activation, kernel_regularizer, name, input_shape):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name, \n",
    "                                  input_shape = input_shape)\n",
    "\n",
    "\n",
    "def Conv2D(filters, kernel_size, strides, padding, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, activation = activation, \n",
    "                                  kernel_regularizer = kernel_regularizer, name = name)\n",
    "\n",
    "def MaxPool(pool_size, strides, padding, name):\n",
    "    return tf.keras.layers.MaxPooling2D(pool_size = pool_size, strides = strides, \n",
    "                                        padding = padding, name = name)\n",
    "\n",
    "def Flatten(name):\n",
    "    return tf.keras.layers.Flatten(name = name)\n",
    "\n",
    "def Dense(units, activation, kernel_regularizer, name):\n",
    "    return tf.keras.layers.Dense(units = units, activation = activation, \n",
    "                                 kernel_regularizer=kernel_regularizer,name = name)\n",
    "\n",
    "def Batch_Normalize():\n",
    "    return tf.keras.layers.BatchNormalization(axis=1)\n",
    "\n",
    "def DropOut(dropout_rate):\n",
    "    return tf.keras.layers.Dropout(dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - To be convereted to functions before posting\n",
    "def set_hyperparameters(param):\n",
    "    \n",
    "    LR_10P_Range = param['LR_10P_Range'] \n",
    "    Mtm_Val = param['Mtm_Val'] \n",
    "    BS_Val = param['BS_Val']  \n",
    "    Cv_Bks_Val= param['Cv_Bks_Val']  \n",
    "    Cv_CvLy_Val= param['Cv_CvLy_Val']  \n",
    "    Cv_PoLy_Val = param['Cv_PoLy_Val'] \n",
    "    Cv_KS_Val = param['Cv_KS_Val']  \n",
    "    Cv_Reg_Val = param['Cv_Reg_Val']\n",
    "    Cv_Fil_Val = param['Cv_Fil_Val']  \n",
    "    Cv_Pd_Val = param['Cv_Pd_Val']  \n",
    "    Cv_Sd_Val = param['Cv_Sd_Val']  \n",
    "    Cv_Av_Val = param['Cv_Av_Val']  \n",
    "    Po_PS_Val = param['Po_PS_Val'] \n",
    "    Po_Pd_Val = param['Po_Pd_Val'] \n",
    "    Dl_Num_Val = param['Dl_Num_Val']  \n",
    "    Dl_Unt_Val = param['Dl_Unt_Val']  \n",
    "    Dl_Reg_Val = param['Dl_Reg_Val']  \n",
    "    Dl_Reg_Val = param['Dl_Reg_Val'] \n",
    "    Bch_Norm_Val = param['Bch_Norm_Val']  \n",
    "    Dpout_Val = param['Dpout_Val']  \n",
    "    Dp_Rate = param['Dp_Rate']\n",
    "    Opt_Algo_Val= param['Opt_Algo_Val']  \n",
    "    Input_Shape = param['Input_Shape']\n",
    "    \n",
    "\n",
    "    LR = pow(10,random.uniform(LR_10P_Range[0],LR_10P_Range[1]))\n",
    "    \n",
    "    random.shuffle(Mtm_Val)\n",
    "    Mtm = Mtm_Val[0]\n",
    "    \n",
    "    random.shuffle(BS_Val)\n",
    "    BS = BS_Val[0]\n",
    "    \n",
    "    random.shuffle(Cv_Bks_Val)\n",
    "    Cv_Bks = Cv_Bks_Val[0]\n",
    "    \n",
    "    Cv_CvLy = []\n",
    "    Cv_KS = []\n",
    "    Cv_Reg = []\n",
    "    Po_PS = []\n",
    "    Po_Sd = []\n",
    "\n",
    "    random.shuffle(Cv_KS_Val)\n",
    "    random.shuffle(Cv_Reg_Val)\n",
    "    random.shuffle(Po_PS_Val)\n",
    "    random.shuffle(Cv_CvLy_Val)\n",
    "    \n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_CvLy.append(Cv_CvLy_Val[0])\n",
    "        Cv_KS.append(Cv_KS_Val[0])\n",
    "        Cv_Reg.append(Cv_Reg_Val[0])\n",
    "        Po_PS.append(Po_PS_Val[0])\n",
    "        Po_Sd.append(Po_PS_Val[0])\n",
    "\n",
    "    Cv_Fil = []    \n",
    "    random.shuffle(Cv_Fil_Val)\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_Fil.append(Cv_Fil_Val[0]*pow(2,math.ceil((i+1)/2)-1))  \n",
    "        \n",
    "    Cv_Pd = []\n",
    "    Cv_Sd = []\n",
    "    Cv_Av = []\n",
    "    Cv_PoLy = []\n",
    "    Po_Pd = []\n",
    "\n",
    "    for i in range(Cv_Bks):\n",
    "        Cv_Pd.append(Cv_Pd_Val)\n",
    "        Cv_Sd.append(Cv_Sd_Val)\n",
    "        Cv_Av.append(Cv_Av_Val)\n",
    "        Cv_PoLy.append(Cv_PoLy_Val)\n",
    "        Po_Pd.append(Po_Pd_Val)\n",
    "    \n",
    "    random.shuffle(Dl_Num_Val)\n",
    "    Dl_Num = Dl_Num_Val[0]\n",
    "    \n",
    "    Dl_Unt =[]\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        random.shuffle(Dl_Unt_Val)\n",
    "        Dl_Unt.append(Dl_Unt_Val[0])\n",
    "        \n",
    "    Dl_Reg = []\n",
    "    random.shuffle(Dl_Reg_Val)\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        Dl_Reg.append(Dl_Reg_Val[0])\n",
    "    \n",
    "    Dl_Av = []\n",
    "\n",
    "    for i in range(Dl_Num):\n",
    "        Dl_Av.append(Dl_Av_Val)\n",
    "\n",
    "    random.shuffle(Bch_Norm_Val)\n",
    "    Bch_Norm = Bch_Norm_Val[0]\n",
    "    \n",
    "    random.shuffle(Dpout_Val)\n",
    "    Dpout = Dpout_Val[0]\n",
    "    \n",
    "    random.shuffle(Opt_Algo_Val)\n",
    "    Opt_Algo = Opt_Algo_Val[0]\n",
    "    \n",
    "    hyperparams = {'LR':LR, 'Mtm':Mtm, 'BS':BS,\n",
    "                    'Cv_Bks':Cv_Bks, 'Cv_CvLy':Cv_CvLy, 'Cv_PoLy':Cv_PoLy, \n",
    "                    'Cv_KS':Cv_KS, 'Cv_Reg':Cv_Reg, 'Cv_Fil':Cv_Fil, \n",
    "                    'Cv_Pd':Cv_Pd, 'Cv_Sd':Cv_Sd, 'Cv_Av':Cv_Av, \n",
    "                    'Po_PS':Po_PS, 'Po_Pd':Po_Pd, 'Po_Sd':Po_Sd,\n",
    "                    'Dl_Num':Dl_Num,'Dl_Unt':Dl_Unt, 'Dl_Reg':Dl_Reg, 'Dl_Av':Dl_Av, \n",
    "                    'Bch_Norm':Bch_Norm, 'Dpout':Dpout, 'Dp_Rate':Dp_Rate,\n",
    "                    'Opt_Algo':Opt_Algo, 'Input_Shape':Input_Shape}\n",
    "    \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(hyperparams):\n",
    "    \n",
    "    Cv_Bks  = hyperparams['Cv_Bks']\n",
    "    Cv_CvLy = hyperparams['Cv_CvLy']\n",
    "    Cv_PoLy = hyperparams['Cv_PoLy']\n",
    "    Cv_KS = hyperparams['Cv_KS']\n",
    "    Cv_Reg = hyperparams['Cv_Reg']\n",
    "    Cv_Fil = hyperparams['Cv_Fil']\n",
    "    Cv_Pd = hyperparams['Cv_Pd']\n",
    "    Cv_Sd = hyperparams['Cv_Sd']\n",
    "    Cv_Av = hyperparams['Cv_Av']\n",
    "    Po_PS = hyperparams['Po_PS']\n",
    "    Po_Pd = hyperparams['Po_Pd']\n",
    "    Po_Sd = hyperparams['Po_Sd']\n",
    "    Dl_Num = hyperparams['Dl_Num']\n",
    "    Dl_Unt = hyperparams['Dl_Unt']\n",
    "    Dl_Reg = hyperparams['Dl_Reg']\n",
    "    Dl_Av = hyperparams['Dl_Av']\n",
    "    Bch_Norm = hyperparams['Bch_Norm']\n",
    "    Dpout = hyperparams['Dpout']\n",
    "    Dp_Rate = hyperparams['Dp_Rate']\n",
    "    \n",
    "    Model = tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(Cv_Bks):\n",
    "\n",
    "        Cv_Bk_Name = 'Blk' + str(i+1)\n",
    "\n",
    "        for j in range(Cv_CvLy[i]):\n",
    "            if (i==0 and j==0):\n",
    "                \n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D_Input(Cv_Fil[i], Cv_KS[i],\n",
    "                                  Cv_Sd[i], Cv_Pd[i],\n",
    "                                  Cv_Av[i], Cv_Reg[i],                         \n",
    "                                  Ly_Name, Input_Shape)\n",
    "                Model.add(Ly)\n",
    "\n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "            else:\n",
    "     \n",
    "\n",
    "                Ly_Name = Cv_Bk_Name + '_Conv' + str(j+1)\n",
    "                Ly = Conv2D(Cv_Fil[i], Cv_KS[i],\n",
    "                            Cv_Sd[i], Cv_Pd[i],\n",
    "                            Cv_Av[i], Cv_Reg[i],                         \n",
    "                            Ly_Name)\n",
    "                Model.add(Ly)\n",
    "            \n",
    "                if Bch_Norm == 'conv' or Bch_Norm == 'all':\n",
    "                    Ly = Batch_Normalize()\n",
    "                    Model.add(Ly)\n",
    "\n",
    "                if Dpout == 'conv' or Dpout == 'all':\n",
    "                    Ly = DropOut(Dp_Rate)\n",
    "                    Model.add(Ly)\n",
    "\n",
    "        for k in range(Cv_PoLy[i]):\n",
    "\n",
    "            Ly_Name = Cv_Bk_Name + '_Pool' + str(k+1)\n",
    "            Ly = MaxPool(Po_PS[i], Po_Sd[i],\n",
    "                         Po_Pd[i], Ly_Name)\n",
    "            Model.add(Ly)\n",
    "        \n",
    "    Model.add(Flatten('Flatten'))\n",
    "\n",
    "    for l in range(Dl_Num):\n",
    "        \n",
    "        Ly_Name = 'Dense' + str(l+1)\n",
    "\n",
    "        Ly = Dense(Dl_Unt[l], Dl_Av[l], Dl_Reg[l], Ly_Name)\n",
    "        Model.add(Ly)\n",
    "\n",
    "        if Bch_Norm == 'dense' or Bch_Norm == 'all':\n",
    "            Ly = Batch_Normalize()\n",
    "            Model.add(Ly)\n",
    "\n",
    "        if Dpout == 'dense' or Dpout == 'all':\n",
    "            Ly = DropOut(Dp_Rate)\n",
    "            Model.add(Ly)\n",
    "\n",
    "    Model.add(Dense(1, 'sigmoid', None, 'Output'))\n",
    "    \n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(es_patience):\n",
    "    callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=es_patience,\n",
    "                                                               verbose=1, restore_best_weights=True)\n",
    "    #callback_model= ModelCheckpoint(filepath='/home/ubuntu/kaggle/flowers/xray_images/Outputs/Best_Model', \n",
    "                                    #save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [callback_early_stopping] #, callback_model]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run_model(Model, Opt_Algo, LR, Mtm, Loss, Metrics):\n",
    "    \n",
    "    if Opt_Algo == 'sgd':\n",
    "        Optimizer = tf.keras.optimizers.SGD(LR, Mtm)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)\n",
    "    \n",
    "    elif Opt_Algo == 'adam':\n",
    "        Optimizer = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "        Model.compile(optimizer = Optimizer, loss = Loss, metrics = Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_data(train_dir, test_dir, batch_size, input_size):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(train_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size) \n",
    "    test_gen = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,color_mode= 'rgb',\n",
    "                                                    class_mode='binary',target_size=input_size)\n",
    "    \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(iter_number, history, hyperparams, File_Name1, File_Name2):\n",
    "    \n",
    "    file = open(File_Name1,\"w\")\n",
    "    file.write(str(hyperparams))\n",
    "    file.close()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(history.history.items())\n",
    "    \n",
    "    df0 = pd.DataFrame()\n",
    "    for i in range(7):\n",
    "        df1 = pd.DataFrame(df[1][i],columns = [df[0][i]])\n",
    "        df0 = pd.concat([df0, df1], axis=1)\n",
    "    df0.to_csv(File_Name2)\n",
    "    \n",
    "    print(\"Files for iteration number \"+ str(iter_number) + \" have been exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape = (224,224,3) \n",
    "Input_Shape_WO_Channel = (224,224) \n",
    "Loss = 'binary_crossentropy'\n",
    "Metrics = ['accuracy','Precision','Recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = tf.keras.regularizers.l2(0.005)\n",
    "Dp_Rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_10P_Range = [-5,-2] # Learning Rate \n",
    "Mtm_Val = [0] # Momentum \n",
    "BS_Val = [16,32,64,128] # Batch Size\n",
    "\n",
    "Cv_Bks_Val = [4,5] # Number of Conv Blocks\n",
    "Cv_CvLy_Val = [1,2] # Num of Conv Layers by Conv Blocks (Can be different in each Conv Block)\n",
    "Cv_PoLy_Val = 1 # Num of Pooling layers by Conv Blocks (Same by each Conv Block)\n",
    "\n",
    "Cv_KS_Val = [3] # Kernerl Size in Conv Layers by Conv Blocks (Same across all Conv Blocks) \n",
    "Cv_Reg_Val = [None] # Regularizaion Type in Conv Layers by Conv Blocks (Same across all Conv Blocks)\n",
    "Cv_Fil_Val = [16,24] # Number of Filters in Conv Layers by Conv Blocks (This fixes the first, rest are followed a-a-2a-2a-4a)\n",
    "Cv_Pd_Val = 'same'\n",
    "Cv_Sd_Val = (1,1)\n",
    "Cv_Av_Val = 'relu'\n",
    "\n",
    "Po_PS_Val = [(2,2)] # Pool Size in Pool Layers by Conv Blocks \n",
    "Po_Pd_Val = 'same'\n",
    "\n",
    "Dl_Num_Val = [1]\n",
    "Dl_Unt_Val = [128,256,512,1024]\n",
    "Dl_Reg_Val = [None]\n",
    "Dl_Av_Val = 'relu'\n",
    "\n",
    "Bch_Norm_Val = ['none']\n",
    "Dpout_Val = ['none']\n",
    "Opt_Algo_Val = ['sgd','adam']\n",
    "\n",
    "param_values = {'LR_10P_Range':LR_10P_Range, 'Mtm_Val':Mtm_Val, 'BS_Val':BS_Val,\n",
    "                'Cv_Bks_Val':Cv_Bks_Val, 'Cv_CvLy_Val':Cv_CvLy_Val, 'Cv_PoLy_Val':Cv_PoLy_Val, \n",
    "                'Cv_KS_Val':Cv_KS_Val, 'Cv_Reg_Val':Cv_Reg_Val, \n",
    "                'Cv_Fil_Val':Cv_Fil_Val, 'Cv_Pd_Val':Cv_Pd_Val, \n",
    "                'Cv_Sd_Val':Cv_Sd_Val, 'Cv_Av_Val':Cv_Av_Val, \n",
    "                'Po_PS_Val':Po_PS_Val, 'Po_Pd_Val':Po_Pd_Val, \n",
    "                'Dl_Num_Val':Dl_Num_Val, 'Dl_Unt_Val':Dl_Unt_Val,\n",
    "                'Dl_Reg_Val':Dl_Reg_Val, 'Dl_Av_Val':Dl_Av_Val, \n",
    "                'Bch_Norm_Val':Bch_Norm_Val, 'Dpout_Val':Dpout_Val,\n",
    "                'Dp_Rate':Dp_Rate, 'Opt_Algo_Val':Opt_Algo_Val,\n",
    "                'Input_Shape':Input_Shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/kaggle/flowers/xray_images/Output_Iter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,805,985\n",
      "Trainable params: 3,803,425\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.00013554828468964876\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 8.3008 - acc: 0.7820 - precision: 0.9592 - recall: 0.7379Epoch 1/20\n",
      "82/82 [==============================] - 59s 715ms/step - loss: 8.2879 - acc: 0.7826 - precision: 0.9591 - recall: 0.7388 - val_loss: 7.5153 - val_acc: 0.3750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 6.4473 - acc: 0.9037 - precision: 0.9804 - recall: 0.8883Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 6.4390 - acc: 0.9043 - precision: 0.9804 - recall: 0.8890 - val_loss: 6.3568 - val_acc: 0.3750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 5.4605 - acc: 0.9480 - precision: 0.9869 - recall: 0.9425Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 5.4565 - acc: 0.9479 - precision: 0.9870 - recall: 0.9422 - val_loss: 5.6185 - val_acc: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 4.8254 - acc: 0.9592 - precision: 0.9850 - recall: 0.9598Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 4.8211 - acc: 0.9595 - precision: 0.9852 - recall: 0.9600 - val_loss: 5.0845 - val_acc: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 4.3185 - acc: 0.9664 - precision: 0.9836 - recall: 0.9710Epoch 1/20\n",
      "82/82 [==============================] - 53s 645ms/step - loss: 4.3156 - acc: 0.9664 - precision: 0.9838 - recall: 0.9708 - val_loss: 4.6707 - val_acc: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.8929 - acc: 0.9695 - precision: 0.9824 - recall: 0.9765Epoch 1/20\n",
      "82/82 [==============================] - 52s 638ms/step - loss: 3.8916 - acc: 0.9691 - precision: 0.9826 - recall: 0.9757 - val_loss: 4.0808 - val_acc: 0.7596 - val_precision: 0.7239 - val_recall: 0.9949\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.5473 - acc: 0.9670 - precision: 0.9775 - recall: 0.9780Epoch 1/20\n",
      "82/82 [==============================] - 52s 636ms/step - loss: 3.5463 - acc: 0.9668 - precision: 0.9773 - recall: 0.9781 - val_loss: 3.7351 - val_acc: 0.7548 - val_precision: 0.7199 - val_recall: 0.9949\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.2364 - acc: 0.9699 - precision: 0.9812 - recall: 0.9783Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 3.2337 - acc: 0.9703 - precision: 0.9814 - recall: 0.9786 - val_loss: 4.3763 - val_acc: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.9419 - acc: 0.9718 - precision: 0.9803 - recall: 0.9818Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 2.9395 - acc: 0.9720 - precision: 0.9804 - recall: 0.9819 - val_loss: 3.2890 - val_acc: 0.7628 - val_precision: 0.7257 - val_recall: 0.9974\n",
      "Epoch 10/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.6701 - acc: 0.9769 - precision: 0.9858 - recall: 0.9830Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 2.6684 - acc: 0.9768 - precision: 0.9858 - recall: 0.9830 - val_loss: 3.0365 - val_acc: 0.7804 - val_precision: 0.7428 - val_recall: 0.9923\n",
      "Epoch 11/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4431 - acc: 0.9790 - precision: 0.9846 - recall: 0.9872Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 2.4417 - acc: 0.9791 - precision: 0.9848 - recall: 0.9871 - val_loss: 4.5752 - val_acc: 0.6282 - val_precision: 0.6270 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2458 - acc: 0.9761 - precision: 0.9836 - recall: 0.9843Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 2.2439 - acc: 0.9764 - precision: 0.9838 - recall: 0.9845 - val_loss: 3.2581 - val_acc: 0.6987 - val_precision: 0.6747 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0373 - acc: 0.9831 - precision: 0.9877 - recall: 0.9895Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 2.0357 - acc: 0.9833 - precision: 0.9879 - recall: 0.9897 - val_loss: 4.4540 - val_acc: 0.6282 - val_precision: 0.6270 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.8620 - acc: 0.9833 - precision: 0.9862 - recall: 0.9914Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 1.8607 - acc: 0.9833 - precision: 0.9864 - recall: 0.9912 - val_loss: 2.4301 - val_acc: 0.7756 - val_precision: 0.7385 - val_recall: 0.9923\n",
      "Epoch 15/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6934 - acc: 0.9864 - precision: 0.9896 - recall: 0.9922Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 1.6931 - acc: 0.9860 - precision: 0.9892 - recall: 0.9920 - val_loss: 4.1199 - val_acc: 0.6442 - val_precision: 0.6373 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5586 - acc: 0.9833 - precision: 0.9900 - recall: 0.9875Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 1.5573 - acc: 0.9835 - precision: 0.9902 - recall: 0.9876 - val_loss: 1.9352 - val_acc: 0.8253 - val_precision: 0.8157 - val_recall: 0.9308\n",
      "Epoch 17/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4241 - acc: 0.9843 - precision: 0.9860 - recall: 0.9929Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 1.4228 - acc: 0.9845 - precision: 0.9862 - recall: 0.9930 - val_loss: 2.1516 - val_acc: 0.7644 - val_precision: 0.7280 - val_recall: 0.9949\n",
      "Epoch 18/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3093 - acc: 0.9849 - precision: 0.9896 - recall: 0.9901Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 1.3080 - acc: 0.9850 - precision: 0.9897 - recall: 0.9902 - val_loss: 4.1445 - val_acc: 0.6282 - val_precision: 0.6270 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1830 - acc: 0.9874 - precision: 0.9911 - recall: 0.9919Epoch 1/20\n",
      "82/82 [==============================] - 52s 632ms/step - loss: 1.1823 - acc: 0.9873 - precision: 0.9912 - recall: 0.9917 - val_loss: 1.6030 - val_acc: 0.8413 - val_precision: 0.8116 - val_recall: 0.9718\n",
      "Epoch 20/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0808 - acc: 0.9885 - precision: 0.9914 - recall: 0.9932Epoch 1/20\n",
      "82/82 [==============================] - 53s 645ms/step - loss: 1.0811 - acc: 0.9883 - precision: 0.9910 - recall: 0.9933 - val_loss: 2.8781 - val_acc: 0.6683 - val_precision: 0.6533 - val_recall: 1.0000\n",
      "Files for iteration number 0 have been exported.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      6416      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 16)        6416      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 16)        6416      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 32)        12832     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 32)          25632     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 9, 9, 32)          25632     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 3, 3, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 3, 3, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 288,881\n",
      "Trainable params: 288,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 4.706597006358179e-05\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.1057 - acc: 0.5307 - precision_2: 0.7543 - recall_2: 0.5459Epoch 1/20\n",
      "41/41 [==============================] - 59s 1s/step - loss: 2.0973 - acc: 0.5326 - precision_2: 0.7547 - recall_2: 0.5494 - val_loss: 1.7586 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7311 - acc: 0.6026 - precision_2: 0.7418 - recall_2: 0.7139Epoch 1/20\n",
      "41/41 [==============================] - 52s 1s/step - loss: 1.7307 - acc: 0.6043 - precision_2: 0.7426 - recall_2: 0.7154 - val_loss: 1.7575 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7179 - acc: 0.6281 - precision_2: 0.7405 - recall_2: 0.7695Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.7184 - acc: 0.6271 - precision_2: 0.7393 - recall_2: 0.7693 - val_loss: 1.7564 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7040 - acc: 0.6551 - precision_2: 0.7415 - recall_2: 0.8221Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.7029 - acc: 0.6561 - precision_2: 0.7421 - recall_2: 0.8230 - val_loss: 1.7553 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7002 - acc: 0.6747 - precision_2: 0.7473 - recall_2: 0.8505Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.7019 - acc: 0.6729 - precision_2: 0.7453 - recall_2: 0.8503 - val_loss: 1.7542 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6954 - acc: 0.6718 - precision_2: 0.7391 - recall_2: 0.8627Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6952 - acc: 0.6724 - precision_2: 0.7395 - recall_2: 0.8630 - val_loss: 1.7533 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6877 - acc: 0.6877 - precision_2: 0.7446 - recall_2: 0.8829Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6883 - acc: 0.6873 - precision_2: 0.7437 - recall_2: 0.8836 - val_loss: 1.7526 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6828 - acc: 0.6946 - precision_2: 0.7434 - recall_2: 0.8998Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6835 - acc: 0.6944 - precision_2: 0.7427 - recall_2: 0.9006 - val_loss: 1.7516 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6854 - acc: 0.7001 - precision_2: 0.7435 - recall_2: 0.9084Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6840 - acc: 0.7017 - precision_2: 0.7458 - recall_2: 0.9079 - val_loss: 1.7508 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6793 - acc: 0.7017 - precision_2: 0.7433 - recall_2: 0.9152Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6788 - acc: 0.7005 - precision_2: 0.7421 - recall_2: 0.9148 - val_loss: 1.7500 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6803 - acc: 0.7064 - precision_2: 0.7424 - recall_2: 0.9268Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6818 - acc: 0.7057 - precision_2: 0.7414 - recall_2: 0.9272 - val_loss: 1.7492 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 12/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6757 - acc: 0.7113 - precision_2: 0.7436 - recall_2: 0.9328Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6756 - acc: 0.7124 - precision_2: 0.7442 - recall_2: 0.9339 - val_loss: 1.7485 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 13/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6708 - acc: 0.7131 - precision_2: 0.7420 - recall_2: 0.9407Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6707 - acc: 0.7132 - precision_2: 0.7422 - recall_2: 0.9406 - val_loss: 1.7478 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 14/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6748 - acc: 0.7152 - precision_2: 0.7410 - recall_2: 0.9473Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6739 - acc: 0.7161 - precision_2: 0.7421 - recall_2: 0.9468 - val_loss: 1.7470 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 15/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6693 - acc: 0.7197 - precision_2: 0.7423 - recall_2: 0.9540Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6694 - acc: 0.7191 - precision_2: 0.7421 - recall_2: 0.9533 - val_loss: 1.7463 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 16/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6690 - acc: 0.7162 - precision_2: 0.7417 - recall_2: 0.9487Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6690 - acc: 0.7159 - precision_2: 0.7413 - recall_2: 0.9486 - val_loss: 1.7457 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 17/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6657 - acc: 0.7203 - precision_2: 0.7430 - recall_2: 0.9535Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6654 - acc: 0.7201 - precision_2: 0.7426 - recall_2: 0.9538 - val_loss: 1.7450 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 18/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6647 - acc: 0.7246 - precision_2: 0.7440 - recall_2: 0.9604Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6660 - acc: 0.7235 - precision_2: 0.7428 - recall_2: 0.9605 - val_loss: 1.7442 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 19/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6660 - acc: 0.7221 - precision_2: 0.7422 - recall_2: 0.9607Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6684 - acc: 0.7201 - precision_2: 0.7401 - recall_2: 0.9605 - val_loss: 1.7435 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Epoch 20/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6632 - acc: 0.7262 - precision_2: 0.7432 - recall_2: 0.9651Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6630 - acc: 0.7262 - precision_2: 0.7429 - recall_2: 0.9657 - val_loss: 1.7428 - val_acc: 0.6250 - val_precision_2: 0.6250 - val_recall_2: 1.0000\n",
      "Files for iteration number 1 have been exported.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 32)        300       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 75, 75, 32)        300       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 25, 25, 64)        100       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 25, 25, 64)        100       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 9, 9, 64)          36        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 261,445\n",
      "Trainable params: 260,579\n",
      "Non-trainable params: 866\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 5.6954618853277926e-05\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.8822 - acc: 0.4463 - precision_4: 0.7351 - recall_4: 0.3996Epoch 1/20\n",
      "41/41 [==============================] - 59s 1s/step - loss: 4.8676 - acc: 0.4492 - precision_4: 0.7350 - recall_4: 0.4044 - val_loss: 3.6691 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.1685 - acc: 0.6087 - precision_4: 0.7498 - recall_4: 0.7103Epoch 1/20\n",
      "41/41 [==============================] - 52s 1s/step - loss: 4.1627 - acc: 0.6093 - precision_4: 0.7502 - recall_4: 0.7107 - val_loss: 3.6755 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.1174 - acc: 0.6258 - precision_4: 0.7446 - recall_4: 0.7564Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 4.1195 - acc: 0.6256 - precision_4: 0.7438 - recall_4: 0.7566 - val_loss: 3.6786 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.0707 - acc: 0.6450 - precision_4: 0.7555 - recall_4: 0.7719Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 4.0728 - acc: 0.6432 - precision_4: 0.7548 - recall_4: 0.7698 - val_loss: 3.6794 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.0402 - acc: 0.6506 - precision_4: 0.7598 - recall_4: 0.7758Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 4.0429 - acc: 0.6503 - precision_4: 0.7586 - recall_4: 0.7763 - val_loss: 3.6795 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.0083 - acc: 0.6557 - precision_4: 0.7586 - recall_4: 0.7867Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 4.0098 - acc: 0.6539 - precision_4: 0.7584 - recall_4: 0.7840 - val_loss: 3.6786 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 4.0073 - acc: 0.6531 - precision_4: 0.7569 - recall_4: 0.7859Epoch 1/20\n",
      " 5/41 [==>...........................] - ETA: 39s - loss: 3.6778 - acc: 0.3750 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00Restoring model weights from the end of the best epoch.\n",
      "41/41 [==============================] - 54s 1s/step - loss: 4.0102 - acc: 0.6536 - precision_4: 0.7567 - recall_4: 0.7866 - val_loss: 3.6778 - val_acc: 0.3750 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 2 have been exported.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 64)        56        \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 14, 14, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 64)        56        \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,061,537\n",
      "Trainable params: 1,060,193\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 0.0001931086191614415\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[None, None, None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9333 - precision_6: 0.9497 - recall_6: 0.9611Epoch 1/20\n",
      "163/163 [==============================] - 56s 342ms/step - loss: 0.1648 - acc: 0.9335 - precision_6: 0.9500 - recall_6: 0.9610 - val_loss: 0.9392 - val_acc: 0.6250 - val_precision_6: 0.6250 - val_recall_6: 1.0000\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9726 - precision_6: 0.9816 - recall_6: 0.9816Epoch 1/20\n",
      "163/163 [==============================] - 52s 319ms/step - loss: 0.0751 - acc: 0.9724 - precision_6: 0.9817 - recall_6: 0.9812 - val_loss: 1.2663 - val_acc: 0.6458 - val_precision_6: 0.6383 - val_recall_6: 1.0000\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9815 - precision_6: 0.9875 - recall_6: 0.9875Epoch 1/20\n",
      "163/163 [==============================] - 52s 318ms/step - loss: 0.0529 - acc: 0.9816 - precision_6: 0.9876 - recall_6: 0.9876 - val_loss: 1.0011 - val_acc: 0.7772 - val_precision_6: 0.7409 - val_recall_6: 0.9897\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9848 - precision_6: 0.9906 - recall_6: 0.9888Epoch 1/20\n",
      "163/163 [==============================] - 52s 320ms/step - loss: 0.0440 - acc: 0.9849 - precision_6: 0.9907 - recall_6: 0.9889 - val_loss: 1.2875 - val_acc: 0.7115 - val_precision_6: 0.6868 - val_recall_6: 0.9897\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9878 - precision_6: 0.9925 - recall_6: 0.9912Epoch 1/20\n",
      "163/163 [==============================] - 52s 320ms/step - loss: 0.0298 - acc: 0.9879 - precision_6: 0.9925 - recall_6: 0.9912 - val_loss: 0.7553 - val_acc: 0.8349 - val_precision_6: 0.8021 - val_recall_6: 0.9769\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9880 - precision_6: 0.9925 - recall_6: 0.9914Epoch 1/20\n",
      "163/163 [==============================] - 52s 320ms/step - loss: 0.0306 - acc: 0.9881 - precision_6: 0.9925 - recall_6: 0.9915 - val_loss: 1.1156 - val_acc: 0.7804 - val_precision_6: 0.7447 - val_recall_6: 0.9872\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9954 - precision_6: 0.9974 - recall_6: 0.9964Epoch 1/20\n",
      "163/163 [==============================] - 52s 317ms/step - loss: 0.0147 - acc: 0.9954 - precision_6: 0.9974 - recall_6: 0.9964 - val_loss: 1.2790 - val_acc: 0.8125 - val_precision_6: 0.7735 - val_recall_6: 0.9897\n",
      "Epoch 8/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9905 - precision_6: 0.9940 - recall_6: 0.9933Epoch 1/20\n",
      "163/163 [==============================] - 52s 320ms/step - loss: 0.0259 - acc: 0.9906 - precision_6: 0.9941 - recall_6: 0.9933 - val_loss: 1.3202 - val_acc: 0.7901 - val_precision_6: 0.7515 - val_recall_6: 0.9923\n",
      "Epoch 9/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9950 - precision_6: 0.9971 - recall_6: 0.9961Epoch 1/20\n",
      "163/163 [==============================] - 52s 319ms/step - loss: 0.0131 - acc: 0.9950 - precision_6: 0.9972 - recall_6: 0.9961 - val_loss: 1.1717 - val_acc: 0.8077 - val_precision_6: 0.7711 - val_recall_6: 0.9846\n",
      "Epoch 10/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9923 - precision_6: 0.9951 - recall_6: 0.9945Epoch 1/20\n",
      "163/163 [==============================] - 51s 316ms/step - loss: 0.0215 - acc: 0.9923 - precision_6: 0.9951 - recall_6: 0.9946 - val_loss: 1.1800 - val_acc: 0.8077 - val_precision_6: 0.7700 - val_recall_6: 0.9872\n",
      "Epoch 11/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9950 - precision_6: 0.9969 - recall_6: 0.9964Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 36s - loss: 1.6841 - acc: 0.7548 - precision_6: 0.7207 - recall_6: 0.9923Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 53s 324ms/step - loss: 0.0130 - acc: 0.9950 - precision_6: 0.9969 - recall_6: 0.9964 - val_loss: 1.6841 - val_acc: 0.7548 - val_precision_6: 0.7207 - val_recall_6: 0.9923\n",
      "Epoch 00011: early stopping\n",
      "Files for iteration number 3 have been exported.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 112, 112, 32)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 112, 112, 32)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 64)        112       \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 14, 128)       56        \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 991,593\n",
      "Trainable params: 990,133\n",
      "Non-trainable params: 1,460\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.002850065526694403\n",
      "Momentum: 0\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2040 - acc: 0.9018 - precision_8: 0.9655 - recall_8: 0.9000Epoch 1/20\n",
      "82/82 [==============================] - 56s 685ms/step - loss: 1.1960 - acc: 0.9026 - precision_8: 0.9657 - recall_8: 0.9009 - val_loss: 2.1521 - val_acc: 0.3750 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.9460 - precision_8: 0.9613 - recall_8: 0.9663Epoch 1/20\n",
      "82/82 [==============================] - 52s 633ms/step - loss: 0.4763 - acc: 0.9461 - precision_8: 0.9612 - recall_8: 0.9665 - val_loss: 5.1870 - val_acc: 0.6250 - val_precision_8: 0.6250 - val_recall_8: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.9639 - precision_8: 0.9759 - recall_8: 0.9754Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 0.2487 - acc: 0.9643 - precision_8: 0.9762 - recall_8: 0.9757 - val_loss: 4.0906 - val_acc: 0.6250 - val_precision_8: 0.6250 - val_recall_8: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9719 - precision_8: 0.9797 - recall_8: 0.9825Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 0.1950 - acc: 0.9716 - precision_8: 0.9792 - recall_8: 0.9827 - val_loss: 3.7443 - val_acc: 0.6250 - val_precision_8: 0.6250 - val_recall_8: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9674 - precision_8: 0.9768 - recall_8: 0.9793Epoch 1/20\n",
      "82/82 [==============================] - 52s 636ms/step - loss: 0.1768 - acc: 0.9674 - precision_8: 0.9768 - recall_8: 0.9794 - val_loss: 7.1696 - val_acc: 0.6250 - val_precision_8: 0.6250 - val_recall_8: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9728 - precision_8: 0.9799 - recall_8: 0.9835Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 0.2414 - acc: 0.9732 - precision_8: 0.9802 - recall_8: 0.9837 - val_loss: 6.7412 - val_acc: 0.6250 - val_precision_8: 0.6250 - val_recall_8: 1.0000\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9732 - precision_8: 0.9815 - recall_8: 0.9825Epoch 1/20\n",
      "10/82 [==>...........................] - ETA: 38s - loss: 4.3204 - acc: 0.6266 - precision_8: 0.6260 - recall_8: 1.0000Restoring model weights from the end of the best epoch.\n",
      "82/82 [==============================] - 54s 661ms/step - loss: 0.1679 - acc: 0.9732 - precision_8: 0.9812 - recall_8: 0.9827 - val_loss: 4.3204 - val_acc: 0.6266 - val_precision_8: 0.6260 - val_recall_8: 1.0000\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 4 have been exported.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,889,345\n",
      "Trainable params: 1,887,809\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 0.009780634303574055\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 4.7993 - acc: 0.8329 - precision_10: 0.8850 - recall_10: 0.8909Epoch 1/20\n",
      "163/163 [==============================] - 56s 344ms/step - loss: 4.7781 - acc: 0.8332 - precision_10: 0.8852 - recall_10: 0.8911 - val_loss: 3.5981 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 2.5160 - acc: 0.8522 - precision_10: 0.8833 - recall_10: 0.9232Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 2.5197 - acc: 0.8526 - precision_10: 0.8836 - recall_10: 0.9231 - val_loss: 4.1365 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 7.1684 - acc: 0.8549 - precision_10: 0.8881 - recall_10: 0.9208Epoch 1/20\n",
      "163/163 [==============================] - 53s 322ms/step - loss: 7.1877 - acc: 0.8553 - precision_10: 0.8881 - recall_10: 0.9213 - val_loss: 13.0753 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 12.9052 - acc: 0.8694 - precision_10: 0.8977 - recall_10: 0.9301Epoch 1/20\n",
      "163/163 [==============================] - 52s 322ms/step - loss: 12.9188 - acc: 0.8696 - precision_10: 0.8979 - recall_10: 0.9303 - val_loss: 17.4723 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 18.5979 - acc: 0.8663 - precision_10: 0.8940 - recall_10: 0.9304Epoch 1/20\n",
      "163/163 [==============================] - 52s 322ms/step - loss: 18.6085 - acc: 0.8664 - precision_10: 0.8941 - recall_10: 0.9303 - val_loss: 22.7152 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 28.3995 - acc: 0.8816 - precision_10: 0.9062 - recall_10: 0.9377Epoch 1/20\n",
      "163/163 [==============================] - 52s 321ms/step - loss: 28.4224 - acc: 0.8821 - precision_10: 0.9067 - recall_10: 0.9378 - val_loss: 34.7825 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 32.6906 - acc: 0.9010 - precision_10: 0.9240 - recall_10: 0.9444Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 35s - loss: 36.6118 - acc: 0.6250 - precision_10: 0.6250 - recall_10: 1.0000Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 53s 326ms/step - loss: 32.6990 - acc: 0.9016 - precision_10: 0.9245 - recall_10: 0.9448 - val_loss: 36.6118 - val_acc: 0.6250 - val_precision_10: 0.6250 - val_recall_10: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n",
      "Files for iteration number 5 have been exported.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      25632     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      25632     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        51264     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,082,369\n",
      "Trainable params: 13,082,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 16\n",
      "Learning_Rate: 0.0025669321374731575\n",
      "Momentum: 0\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.8572 - acc: 0.7775 - precision_12: 0.8012 - recall_12: 0.9320Epoch 1/20\n",
      "326/326 [==============================] - 59s 182ms/step - loss: 1.8532 - acc: 0.7782 - precision_12: 0.8016 - recall_12: 0.9321 - val_loss: 1.0451 - val_acc: 0.6571 - val_precision_12: 0.6462 - val_recall_12: 0.9974\n",
      "Epoch 2/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.5833 - acc: 0.8929 - precision_12: 0.9223 - recall_12: 0.9345Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 0.5829 - acc: 0.8930 - precision_12: 0.9225 - recall_12: 0.9345 - val_loss: 1.0695 - val_acc: 0.6282 - val_precision_12: 0.6270 - val_recall_12: 1.0000\n",
      "Epoch 3/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.9294 - precision_12: 0.9529 - recall_12: 0.9521Epoch 1/20\n",
      "326/326 [==============================] - 56s 170ms/step - loss: 0.4028 - acc: 0.9296 - precision_12: 0.9530 - recall_12: 0.9523 - val_loss: 0.8979 - val_acc: 0.6426 - val_precision_12: 0.6362 - val_recall_12: 1.0000\n",
      "Epoch 4/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.9413 - precision_12: 0.9596 - recall_12: 0.9614Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 0.3287 - acc: 0.9413 - precision_12: 0.9598 - recall_12: 0.9613 - val_loss: 0.9298 - val_acc: 0.6298 - val_precision_12: 0.6280 - val_recall_12: 1.0000\n",
      "Epoch 5/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9473 - precision_12: 0.9684 - recall_12: 0.9604Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 0.2703 - acc: 0.9475 - precision_12: 0.9685 - recall_12: 0.9605 - val_loss: 1.3960 - val_acc: 0.6250 - val_precision_12: 0.6250 - val_recall_12: 1.0000\n",
      "Epoch 6/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9490 - precision_12: 0.9668 - recall_12: 0.9646Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 0.2255 - acc: 0.9490 - precision_12: 0.9669 - recall_12: 0.9644 - val_loss: 0.9977 - val_acc: 0.6378 - val_precision_12: 0.6336 - val_recall_12: 0.9974\n",
      "Epoch 7/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9594 - precision_12: 0.9738 - recall_12: 0.9715Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 0.1949 - acc: 0.9594 - precision_12: 0.9736 - recall_12: 0.9716 - val_loss: 1.2883 - val_acc: 0.6250 - val_precision_12: 0.6250 - val_recall_12: 1.0000\n",
      "Epoch 8/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9588 - precision_12: 0.9730 - recall_12: 0.9715Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 0.2078 - acc: 0.9590 - precision_12: 0.9731 - recall_12: 0.9716 - val_loss: 1.1558 - val_acc: 0.6282 - val_precision_12: 0.6270 - val_recall_12: 1.0000\n",
      "Epoch 9/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9575 - precision_12: 0.9747 - recall_12: 0.9679Epoch 1/20\n",
      " 39/326 [==>...........................] - ETA: 37s - loss: 1.2257 - acc: 0.6250 - precision_12: 0.6250 - recall_12: 1.0000Restoring model weights from the end of the best epoch.\n",
      "326/326 [==============================] - 56s 173ms/step - loss: 0.2061 - acc: 0.9574 - precision_12: 0.9745 - recall_12: 0.9680 - val_loss: 1.2257 - val_acc: 0.6250 - val_precision_12: 0.6250 - val_recall_12: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "Files for iteration number 6 have been exported.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 75, 75, 16)        300       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 25, 25, 32)        100       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 25, 25, 32)        100       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               663808    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 753,813\n",
      "Trainable params: 751,387\n",
      "Non-trainable params: 2,426\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.00011654418843823046\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[None, None, None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0154 - acc: 0.7215 - precision_14: 0.9183 - recall_14: 0.6854Epoch 1/20\n",
      "82/82 [==============================] - 57s 690ms/step - loss: 1.0161 - acc: 0.7214 - precision_14: 0.9190 - recall_14: 0.6854 - val_loss: 1.1860 - val_acc: 0.6250 - val_precision_14: 0.6250 - val_recall_14: 1.0000\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8214 - acc: 0.8492 - precision_14: 0.9588 - recall_14: 0.8328Epoch 1/20\n",
      "82/82 [==============================] - 53s 640ms/step - loss: 0.8198 - acc: 0.8501 - precision_14: 0.9590 - recall_14: 0.8338 - val_loss: 1.3035 - val_acc: 0.6250 - val_precision_14: 0.6250 - val_recall_14: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7298 - acc: 0.9018 - precision_14: 0.9595 - recall_14: 0.9058Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 0.7299 - acc: 0.9022 - precision_14: 0.9598 - recall_14: 0.9063 - val_loss: 1.0939 - val_acc: 0.6250 - val_precision_14: 0.6250 - val_recall_14: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6732 - acc: 0.9146 - precision_14: 0.9537 - recall_14: 0.9303Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 0.6729 - acc: 0.9145 - precision_14: 0.9530 - recall_14: 0.9308 - val_loss: 1.1782 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6589 - acc: 0.9262 - precision_14: 0.9549 - recall_14: 0.9454Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 0.6583 - acc: 0.9264 - precision_14: 0.9544 - recall_14: 0.9461 - val_loss: 1.8129 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.9336 - precision_14: 0.9571 - recall_14: 0.9536Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 0.6219 - acc: 0.9335 - precision_14: 0.9568 - recall_14: 0.9535 - val_loss: 3.2629 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5873 - acc: 0.9441 - precision_14: 0.9631 - recall_14: 0.9616Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 0.5871 - acc: 0.9440 - precision_14: 0.9626 - recall_14: 0.9621 - val_loss: 4.8173 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5653 - acc: 0.9464 - precision_14: 0.9635 - recall_14: 0.9645Epoch 1/20\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 0.5679 - acc: 0.9463 - precision_14: 0.9632 - recall_14: 0.9646 - val_loss: 6.1458 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5551 - acc: 0.9453 - precision_14: 0.9637 - recall_14: 0.9627Epoch 1/20\n",
      "10/82 [==>...........................] - ETA: 39s - loss: 3.4447 - acc: 0.3750 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00Restoring model weights from the end of the best epoch.\n",
      "82/82 [==============================] - 54s 661ms/step - loss: 0.5551 - acc: 0.9454 - precision_14: 0.9638 - recall_14: 0.9626 - val_loss: 3.4447 - val_acc: 0.3750 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 00009: early stopping\n",
      "Files for iteration number 7 have been exported.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 112, 112, 32)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 12,924,097\n",
      "Trainable params: 12,922,241\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 5.8666766121678776e-05\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.4604 - acc: 0.9247 - precision_16: 0.9867 - recall_16: 0.9109Epoch 1/20\n",
      "82/82 [==============================] - 57s 696ms/step - loss: 3.4564 - acc: 0.9254 - precision_16: 0.9869 - recall_16: 0.9117 - val_loss: 3.6729 - val_acc: 0.6250 - val_precision_16: 0.6250 - val_recall_16: 1.0000\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.9081 - acc: 0.9746 - precision_16: 0.9918 - recall_16: 0.9739Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 2.9060 - acc: 0.9743 - precision_16: 0.9913 - recall_16: 0.9739 - val_loss: 3.4134 - val_acc: 0.6250 - val_precision_16: 0.6250 - val_recall_16: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.5286 - acc: 0.9823 - precision_16: 0.9924 - recall_16: 0.9838Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 2.5262 - acc: 0.9826 - precision_16: 0.9925 - recall_16: 0.9840 - val_loss: 3.2106 - val_acc: 0.6250 - val_precision_16: 0.6250 - val_recall_16: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2190 - acc: 0.9918 - precision_16: 0.9963 - recall_16: 0.9927Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 2.2178 - acc: 0.9918 - precision_16: 0.9964 - recall_16: 0.9925 - val_loss: 3.2369 - val_acc: 0.6298 - val_precision_16: 0.6280 - val_recall_16: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9736 - acc: 0.9951 - precision_16: 0.9976 - recall_16: 0.9958Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 1.9720 - acc: 0.9952 - precision_16: 0.9977 - recall_16: 0.9959 - val_loss: 2.8298 - val_acc: 0.6619 - val_precision_16: 0.6489 - val_recall_16: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.7674 - acc: 0.9959 - precision_16: 0.9982 - recall_16: 0.9963Epoch 1/20\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 1.7662 - acc: 0.9960 - precision_16: 0.9982 - recall_16: 0.9964 - val_loss: 3.3351 - val_acc: 0.6571 - val_precision_16: 0.6457 - val_recall_16: 1.0000\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6014 - acc: 0.9961 - precision_16: 0.9987 - recall_16: 0.9961Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 1.6005 - acc: 0.9962 - precision_16: 0.9987 - recall_16: 0.9961 - val_loss: 3.2862 - val_acc: 0.6731 - val_precision_16: 0.6566 - val_recall_16: 1.0000\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4585 - acc: 0.9953 - precision_16: 0.9976 - recall_16: 0.9961Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 1.4577 - acc: 0.9952 - precision_16: 0.9977 - recall_16: 0.9959 - val_loss: 2.2136 - val_acc: 0.7660 - val_precision_16: 0.7285 - val_recall_16: 0.9974\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3310 - acc: 0.9973 - precision_16: 0.9992 - recall_16: 0.9971Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 1.3302 - acc: 0.9973 - precision_16: 0.9992 - recall_16: 0.9972 - val_loss: 2.0737 - val_acc: 0.7676 - val_precision_16: 0.7307 - val_recall_16: 0.9949\n",
      "Epoch 10/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.2160 - acc: 0.9988 - precision_16: 0.9997 - recall_16: 0.9987Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 1.2153 - acc: 0.9988 - precision_16: 0.9997 - recall_16: 0.9987 - val_loss: 1.7983 - val_acc: 0.7949 - val_precision_16: 0.7569 - val_recall_16: 0.9897\n",
      "Epoch 11/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1204 - acc: 0.9983 - precision_16: 0.9997 - recall_16: 0.9979Epoch 1/20\n",
      "82/82 [==============================] - 54s 658ms/step - loss: 1.1198 - acc: 0.9983 - precision_16: 0.9997 - recall_16: 0.9979 - val_loss: 1.8865 - val_acc: 0.7644 - val_precision_16: 0.7288 - val_recall_16: 0.9923\n",
      "Epoch 12/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0753 - acc: 0.9911 - precision_16: 0.9971 - recall_16: 0.9909Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 1.0746 - acc: 0.9912 - precision_16: 0.9971 - recall_16: 0.9910 - val_loss: 1.6382 - val_acc: 0.7788 - val_precision_16: 0.8231 - val_recall_16: 0.8231\n",
      "Epoch 13/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9937 - acc: 0.9969 - precision_16: 0.9995 - recall_16: 0.9963Epoch 1/20\n",
      "82/82 [==============================] - 54s 656ms/step - loss: 0.9934 - acc: 0.9969 - precision_16: 0.9995 - recall_16: 0.9964 - val_loss: 1.9095 - val_acc: 0.7532 - val_precision_16: 0.7193 - val_recall_16: 0.9923\n",
      "Epoch 14/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.9242 - acc: 0.9981 - precision_16: 0.9995 - recall_16: 0.9979Epoch 1/20\n",
      "82/82 [==============================] - 52s 639ms/step - loss: 0.9239 - acc: 0.9981 - precision_16: 0.9995 - recall_16: 0.9979 - val_loss: 2.2500 - val_acc: 0.6955 - val_precision_16: 0.6730 - val_recall_16: 0.9974\n",
      "Epoch 15/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8724 - acc: 0.9971 - precision_16: 0.9997 - recall_16: 0.9963Epoch 1/20\n",
      "82/82 [==============================] - 53s 643ms/step - loss: 0.8720 - acc: 0.9971 - precision_16: 0.9997 - recall_16: 0.9964 - val_loss: 1.7642 - val_acc: 0.7580 - val_precision_16: 0.7234 - val_recall_16: 0.9923\n",
      "Epoch 16/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8182 - acc: 0.9984 - precision_16: 0.9992 - recall_16: 0.9987Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 0.8178 - acc: 0.9985 - precision_16: 0.9992 - recall_16: 0.9987 - val_loss: 1.5082 - val_acc: 0.8061 - val_precision_16: 0.7685 - val_recall_16: 0.9872\n",
      "Epoch 17/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7739 - acc: 0.9984 - precision_16: 0.9997 - recall_16: 0.9982Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 0.7736 - acc: 0.9985 - precision_16: 0.9997 - recall_16: 0.9982 - val_loss: 1.8763 - val_acc: 0.7516 - val_precision_16: 0.7188 - val_recall_16: 0.9897\n",
      "Epoch 18/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7296 - acc: 0.9998 - precision_16: 0.9997 - recall_16: 1.0000Epoch 1/20\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 0.7293 - acc: 0.9998 - precision_16: 0.9997 - recall_16: 1.0000 - val_loss: 1.2580 - val_acc: 0.8189 - val_precision_16: 0.7867 - val_recall_16: 0.9744\n",
      "Epoch 19/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6953 - acc: 0.9984 - precision_16: 0.9995 - recall_16: 0.9984Epoch 1/20\n",
      "82/82 [==============================] - 54s 654ms/step - loss: 0.6950 - acc: 0.9985 - precision_16: 0.9995 - recall_16: 0.9985 - val_loss: 2.3492 - val_acc: 0.6923 - val_precision_16: 0.6707 - val_recall_16: 0.9974\n",
      "Epoch 20/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.6885 - acc: 0.9917 - precision_16: 0.9974 - recall_16: 0.9914Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 0.6883 - acc: 0.9916 - precision_16: 0.9974 - recall_16: 0.9912 - val_loss: 1.4655 - val_acc: 0.7981 - val_precision_16: 0.7661 - val_recall_16: 0.9744\n",
      "Files for iteration number 8 have been exported.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 14, 14, 64)        56        \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 14, 14, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 14, 14, 64)        56        \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,146,721\n",
      "Trainable params: 1,144,065\n",
      "Non-trainable params: 2,656\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 0.001086968677332496\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 6.0497 - acc: 0.5110 - precision_18: 0.7458 - recall_18: 0.5170Epoch 1/20\n",
      "41/41 [==============================] - 56s 1s/step - loss: 6.0518 - acc: 0.5113 - precision_18: 0.7474 - recall_18: 0.5169 - val_loss: 5.7275 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 6.0070 - acc: 0.5314 - precision_18: 0.7637 - recall_18: 0.5345Epoch 1/20\n",
      "41/41 [==============================] - 52s 1s/step - loss: 6.0044 - acc: 0.5336 - precision_18: 0.7651 - recall_18: 0.5370 - val_loss: 5.7143 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.9483 - acc: 0.5617 - precision_18: 0.7870 - recall_18: 0.5604Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.9472 - acc: 0.5621 - precision_18: 0.7892 - recall_18: 0.5603 - val_loss: 5.6985 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.8572 - acc: 0.5882 - precision_18: 0.8083 - recall_18: 0.5832Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.8560 - acc: 0.5884 - precision_18: 0.8095 - recall_18: 0.5832 - val_loss: 5.6989 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.8489 - acc: 0.5967 - precision_18: 0.8212 - recall_18: 0.5825Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 5.8504 - acc: 0.5955 - precision_18: 0.8229 - recall_18: 0.5804 - val_loss: 5.6967 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.7759 - acc: 0.6285 - precision_18: 0.8407 - recall_18: 0.6163Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.7773 - acc: 0.6267 - precision_18: 0.8404 - recall_18: 0.6142 - val_loss: 5.7064 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.7570 - acc: 0.6390 - precision_18: 0.8535 - recall_18: 0.6208Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.7549 - acc: 0.6390 - precision_18: 0.8534 - recall_18: 0.6206 - val_loss: 5.7293 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.7198 - acc: 0.6616 - precision_18: 0.8666 - recall_18: 0.6425Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 5.7191 - acc: 0.6616 - precision_18: 0.8673 - recall_18: 0.6428 - val_loss: 5.7393 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.7017 - acc: 0.6614 - precision_18: 0.8684 - recall_18: 0.6426Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.7004 - acc: 0.6618 - precision_18: 0.8661 - recall_18: 0.6444 - val_loss: 5.7847 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.6639 - acc: 0.6830 - precision_18: 0.8844 - recall_18: 0.6595Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 5.6613 - acc: 0.6846 - precision_18: 0.8847 - recall_18: 0.6617 - val_loss: 5.8192 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 5.6185 - acc: 0.7081 - precision_18: 0.8984 - recall_18: 0.6848Epoch 1/20\n",
      " 5/41 [==>...........................] - ETA: 39s - loss: 5.8139 - acc: 0.6250 - precision_18: 0.6250 - recall_18: 1.0000Restoring model weights from the end of the best epoch.\n",
      "41/41 [==============================] - 54s 1s/step - loss: 5.6174 - acc: 0.7086 - precision_18: 0.8985 - recall_18: 0.6852 - val_loss: 5.8139 - val_acc: 0.6250 - val_precision_18: 0.6250 - val_recall_18: 1.0000\n",
      "Epoch 00011: early stopping\n",
      "Files for iteration number 9 have been exported.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 75, 75, 32)        300       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 25, 25, 64)        100       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               1327360   \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,469,073\n",
      "Trainable params: 1,467,209\n",
      "Non-trainable params: 1,864\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 16\n",
      "Learning_Rate: 0.00023207121818079272\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.8531 - acc: 0.7467 - precision_20: 0.9251 - recall_20: 0.7168Epoch 1/20\n",
      "326/326 [==============================] - 61s 186ms/step - loss: 3.8543 - acc: 0.7467 - precision_20: 0.9254 - recall_20: 0.7169 - val_loss: 10.3063 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 2/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.6382 - acc: 0.8250 - precision_20: 0.9435 - recall_20: 0.8131Epoch 1/20\n",
      "326/326 [==============================] - 56s 172ms/step - loss: 3.6386 - acc: 0.8248 - precision_20: 0.9434 - recall_20: 0.8129 - val_loss: 32.2190 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 3/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.5180 - acc: 0.8644 - precision_20: 0.9509 - recall_20: 0.8620Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 3.5183 - acc: 0.8643 - precision_20: 0.9510 - recall_20: 0.8617 - val_loss: 40.9068 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 4/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.4298 - acc: 0.8750 - precision_20: 0.9492 - recall_20: 0.8789Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 3.4295 - acc: 0.8752 - precision_20: 0.9490 - recall_20: 0.8792 - val_loss: 38.8718 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 5/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.3786 - acc: 0.8838 - precision_20: 0.9465 - recall_20: 0.8941Epoch 1/20\n",
      "326/326 [==============================] - 56s 172ms/step - loss: 3.3784 - acc: 0.8840 - precision_20: 0.9467 - recall_20: 0.8942 - val_loss: 31.2142 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 6/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.2953 - acc: 0.9027 - precision_20: 0.9577 - recall_20: 0.9091Epoch 1/20\n",
      "326/326 [==============================] - 56s 172ms/step - loss: 3.2952 - acc: 0.9028 - precision_20: 0.9579 - recall_20: 0.9092 - val_loss: 34.5438 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 7/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.2398 - acc: 0.9042 - precision_20: 0.9471 - recall_20: 0.9226Epoch 1/20\n",
      " 39/326 [==>...........................] - ETA: 37s - loss: 35.1103 - acc: 0.3750 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00Restoring model weights from the end of the best epoch.\n",
      "326/326 [==============================] - 57s 175ms/step - loss: 3.2398 - acc: 0.9043 - precision_20: 0.9473 - recall_20: 0.9226 - val_loss: 35.1103 - val_acc: 0.3750 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 10 have been exported.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,321,473\n",
      "Trainable params: 3,318,425\n",
      "Non-trainable params: 3,048\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.0002264055518274318\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None]\n",
      "Regularization_Dense_Layers[None, None, None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.7745 - precision_22: 0.9581 - recall_22: 0.7286Epoch 1/20\n",
      "82/82 [==============================] - 57s 694ms/step - loss: 0.5056 - acc: 0.7755 - precision_22: 0.9583 - recall_22: 0.7295 - val_loss: 0.8320 - val_acc: 0.6250 - val_precision_22: 0.6250 - val_recall_22: 1.0000\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.8942 - precision_22: 0.9815 - recall_22: 0.8740Epoch 1/20\n",
      "82/82 [==============================] - 52s 635ms/step - loss: 0.2766 - acc: 0.8951 - precision_22: 0.9818 - recall_22: 0.8751 - val_loss: 1.2569 - val_acc: 0.6250 - val_precision_22: 0.6250 - val_recall_22: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9369 - precision_22: 0.9837 - recall_22: 0.9305Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 0.1941 - acc: 0.9375 - precision_22: 0.9839 - recall_22: 0.9311 - val_loss: 1.2455 - val_acc: 0.6250 - val_precision_22: 0.6250 - val_recall_22: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9557 - precision_22: 0.9852 - recall_22: 0.9548Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 52s 635ms/step - loss: 0.1378 - acc: 0.9555 - precision_22: 0.9853 - recall_22: 0.9543 - val_loss: 1.5051 - val_acc: 0.6250 - val_precision_22: 0.6250 - val_recall_22: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9672 - precision_22: 0.9867 - recall_22: 0.9689Epoch 1/20\n",
      "82/82 [==============================] - 51s 624ms/step - loss: 0.1074 - acc: 0.9668 - precision_22: 0.9866 - recall_22: 0.9685 - val_loss: 0.9492 - val_acc: 0.6619 - val_precision_22: 0.6489 - val_recall_22: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9707 - precision_22: 0.9839 - recall_22: 0.9765Epoch 1/20\n",
      "82/82 [==============================] - 52s 637ms/step - loss: 0.1040 - acc: 0.9709 - precision_22: 0.9841 - recall_22: 0.9765 - val_loss: 0.7201 - val_acc: 0.7468 - val_precision_22: 0.7125 - val_recall_22: 0.9974\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9771 - precision_22: 0.9892 - recall_22: 0.9799Epoch 1/20\n",
      "82/82 [==============================] - 52s 634ms/step - loss: 0.0804 - acc: 0.9774 - precision_22: 0.9893 - recall_22: 0.9801 - val_loss: 1.1158 - val_acc: 0.6987 - val_precision_22: 0.6747 - val_recall_22: 1.0000\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9821 - precision_22: 0.9918 - recall_22: 0.9841Epoch 1/20\n",
      "82/82 [==============================] - 52s 628ms/step - loss: 0.0619 - acc: 0.9820 - precision_22: 0.9914 - recall_22: 0.9843 - val_loss: 1.0416 - val_acc: 0.7163 - val_precision_22: 0.6878 - val_recall_22: 1.0000\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9847 - precision_22: 0.9926 - recall_22: 0.9867Epoch 1/20\n",
      "82/82 [==============================] - 53s 643ms/step - loss: 0.0586 - acc: 0.9849 - precision_22: 0.9927 - recall_22: 0.9868 - val_loss: 1.0884 - val_acc: 0.7147 - val_precision_22: 0.6873 - val_recall_22: 0.9974\n",
      "Epoch 10/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9872 - precision_22: 0.9919 - recall_22: 0.9909Epoch 1/20\n",
      "82/82 [==============================] - 51s 627ms/step - loss: 0.0462 - acc: 0.9866 - precision_22: 0.9912 - recall_22: 0.9907 - val_loss: 1.2031 - val_acc: 0.7067 - val_precision_22: 0.6813 - val_recall_22: 0.9974\n",
      "Epoch 11/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9899 - precision_22: 0.9937 - recall_22: 0.9927Epoch 1/20\n",
      "82/82 [==============================] - 51s 622ms/step - loss: 0.0341 - acc: 0.9898 - precision_22: 0.9935 - recall_22: 0.9928 - val_loss: 0.7404 - val_acc: 0.8029 - val_precision_22: 0.7665 - val_recall_22: 0.9846\n",
      "Epoch 12/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9885 - precision_22: 0.9924 - recall_22: 0.9922Epoch 1/20\n",
      "10/82 [==>...........................] - ETA: 37s - loss: 1.0116 - acc: 0.7420 - precision_22: 0.7093 - recall_22: 0.9949Restoring model weights from the end of the best epoch.\n",
      "82/82 [==============================] - 54s 656ms/step - loss: 0.0364 - acc: 0.9885 - precision_22: 0.9925 - recall_22: 0.9920 - val_loss: 1.0116 - val_acc: 0.7420 - val_precision_22: 0.7093 - val_recall_22: 0.9949\n",
      "Epoch 00012: early stopping\n",
      "Files for iteration number 11 have been exported.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 75, 75, 32)        300       \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 75, 75, 32)        300       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 25, 25, 64)        100       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 9, 9, 64)          36        \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 9, 9, 64)          36        \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 262,405\n",
      "Trainable params: 261,059\n",
      "Non-trainable params: 1,346\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 16\n",
      "Learning_Rate: 0.0008234940219440937\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.1970 - acc: 0.9194 - precision_24: 0.9707 - recall_24: 0.9192Epoch 1/20\n",
      "326/326 [==============================] - 60s 185ms/step - loss: 1.1956 - acc: 0.9195 - precision_24: 0.9708 - recall_24: 0.9192 - val_loss: 1.1445 - val_acc: 0.7083 - val_precision_24: 0.6825 - val_recall_24: 0.9974\n",
      "Epoch 2/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.5016 - acc: 0.9483 - precision_24: 0.9617 - recall_24: 0.9689Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.5012 - acc: 0.9482 - precision_24: 0.9616 - recall_24: 0.9690 - val_loss: 0.9431 - val_acc: 0.7837 - val_precision_24: 0.7447 - val_recall_24: 0.9949\n",
      "Epoch 3/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.2635 - acc: 0.9623 - precision_24: 0.9717 - recall_24: 0.9777Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.2639 - acc: 0.9620 - precision_24: 0.9718 - recall_24: 0.9773 - val_loss: 0.5283 - val_acc: 0.8446 - val_precision_24: 0.8178 - val_recall_24: 0.9667\n",
      "Epoch 4/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9598 - precision_24: 0.9687 - recall_24: 0.9775Epoch 1/20\n",
      "326/326 [==============================] - 54s 167ms/step - loss: 0.1911 - acc: 0.9597 - precision_24: 0.9688 - recall_24: 0.9773 - val_loss: 1.9176 - val_acc: 0.6667 - val_precision_24: 0.6522 - val_recall_24: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9683 - precision_24: 0.9761 - recall_24: 0.9814Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 0.1452 - acc: 0.9680 - precision_24: 0.9756 - recall_24: 0.9814 - val_loss: 1.0319 - val_acc: 0.7083 - val_precision_24: 0.6818 - val_recall_24: 1.0000\n",
      "Epoch 6/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9687 - precision_24: 0.9766 - recall_24: 0.9814Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.1261 - acc: 0.9688 - precision_24: 0.9766 - recall_24: 0.9814 - val_loss: 0.3595 - val_acc: 0.8846 - val_precision_24: 0.8681 - val_recall_24: 0.9615\n",
      "Epoch 7/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9744 - precision_24: 0.9804 - recall_24: 0.9853Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.1085 - acc: 0.9735 - precision_24: 0.9795 - recall_24: 0.9850 - val_loss: 0.9061 - val_acc: 0.7933 - val_precision_24: 0.7534 - val_recall_24: 0.9949\n",
      "Epoch 8/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9727 - precision_24: 0.9814 - recall_24: 0.9819Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.1084 - acc: 0.9728 - precision_24: 0.9814 - recall_24: 0.9819 - val_loss: 1.2340 - val_acc: 0.6827 - val_precision_24: 0.6633 - val_recall_24: 1.0000\n",
      "Epoch 9/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9738 - precision_24: 0.9809 - recall_24: 0.9839Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 0.0989 - acc: 0.9735 - precision_24: 0.9810 - recall_24: 0.9835 - val_loss: 1.5104 - val_acc: 0.5272 - val_precision_24: 0.9612 - val_recall_24: 0.2538\n",
      "Epoch 10/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9713 - precision_24: 0.9788 - recall_24: 0.9827Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 0.1072 - acc: 0.9714 - precision_24: 0.9789 - recall_24: 0.9827 - val_loss: 1.0796 - val_acc: 0.7179 - val_precision_24: 0.6890 - val_recall_24: 1.0000\n",
      "Epoch 11/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9783 - precision_24: 0.9827 - recall_24: 0.9881Epoch 1/20\n",
      "326/326 [==============================] - 54s 167ms/step - loss: 0.0857 - acc: 0.9783 - precision_24: 0.9828 - recall_24: 0.9881 - val_loss: 1.5079 - val_acc: 0.6843 - val_precision_24: 0.6650 - val_recall_24: 0.9974\n",
      "Epoch 12/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9763 - precision_24: 0.9850 - recall_24: 0.9832Epoch 1/20\n",
      " 39/326 [==>...........................] - ETA: 37s - loss: 1.1457 - acc: 0.7404 - precision_24: 0.7065 - recall_24: 1.0000Restoring model weights from the end of the best epoch.\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 0.0890 - acc: 0.9764 - precision_24: 0.9850 - recall_24: 0.9832 - val_loss: 1.1457 - val_acc: 0.7404 - val_precision_24: 0.7065 - val_recall_24: 1.0000\n",
      "Epoch 00012: early stopping\n",
      "Files for iteration number 12 have been exported.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 28, 28, 32)        112       \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 14, 14, 64)        56        \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,913,577\n",
      "Trainable params: 1,910,437\n",
      "Non-trainable params: 3,140\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.0005437441132273641\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 6.9666 - acc: 0.9290 - precision_26: 0.9758 - recall_26: 0.9274Epoch 1/20\n",
      "82/82 [==============================] - 59s 716ms/step - loss: 6.9490 - acc: 0.9294 - precision_26: 0.9758 - recall_26: 0.9280 - val_loss: 6.6556 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 4.3892 - acc: 0.9701 - precision_26: 0.9809 - recall_26: 0.9788Epoch 1/20\n",
      "82/82 [==============================] - 52s 637ms/step - loss: 4.3776 - acc: 0.9703 - precision_26: 0.9809 - recall_26: 0.9791 - val_loss: 6.1761 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.8397 - acc: 0.9753 - precision_26: 0.9841 - recall_26: 0.9828Epoch 1/20\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 2.8333 - acc: 0.9755 - precision_26: 0.9840 - recall_26: 0.9830 - val_loss: 3.4728 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9959 - acc: 0.9688 - precision_26: 0.9781 - recall_26: 0.9799Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 1.9924 - acc: 0.9688 - precision_26: 0.9779 - recall_26: 0.9801 - val_loss: 3.7184 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4444 - acc: 0.9724 - precision_26: 0.9809 - recall_26: 0.9820Epoch 1/20\n",
      "82/82 [==============================] - 53s 642ms/step - loss: 1.4416 - acc: 0.9726 - precision_26: 0.9812 - recall_26: 0.9819 - val_loss: 2.3017 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.9794 - precision_26: 0.9849 - recall_26: 0.9874Epoch 1/20\n",
      "82/82 [==============================] - 52s 640ms/step - loss: 1.0970 - acc: 0.9793 - precision_26: 0.9851 - recall_26: 0.9871 - val_loss: 3.3259 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.8598 - acc: 0.9808 - precision_26: 0.9849 - recall_26: 0.9893Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 0.8584 - acc: 0.9810 - precision_26: 0.9851 - recall_26: 0.9894 - val_loss: 2.4455 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7028 - acc: 0.9792 - precision_26: 0.9859 - recall_26: 0.9862Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 0.7014 - acc: 0.9795 - precision_26: 0.9861 - recall_26: 0.9863 - val_loss: 2.9664 - val_acc: 0.6250 - val_precision_26: 0.6250 - val_recall_26: 1.0000\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.9800 - precision_26: 0.9872 - recall_26: 0.9859Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 0.5815 - acc: 0.9801 - precision_26: 0.9873 - recall_26: 0.9858 - val_loss: 1.8417 - val_acc: 0.6875 - val_precision_26: 0.6672 - val_recall_26: 0.9974\n",
      "Epoch 10/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.9858 - precision_26: 0.9901 - recall_26: 0.9909Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 0.4842 - acc: 0.9860 - precision_26: 0.9902 - recall_26: 0.9910 - val_loss: 2.2288 - val_acc: 0.6282 - val_precision_26: 0.6270 - val_recall_26: 1.0000\n",
      "Epoch 11/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.9847 - precision_26: 0.9893 - recall_26: 0.9901Epoch 1/20\n",
      "82/82 [==============================] - 52s 634ms/step - loss: 0.4183 - acc: 0.9847 - precision_26: 0.9892 - recall_26: 0.9902 - val_loss: 1.2486 - val_acc: 0.7420 - val_precision_26: 0.7198 - val_recall_26: 0.9615\n",
      "Epoch 12/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.9800 - precision_26: 0.9867 - recall_26: 0.9864Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 0.3998 - acc: 0.9801 - precision_26: 0.9868 - recall_26: 0.9863 - val_loss: 7.6833 - val_acc: 0.3798 - val_precision_26: 1.0000 - val_recall_26: 0.0077\n",
      "Epoch 13/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.9856 - precision_26: 0.9906 - recall_26: 0.9901Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 0.3473 - acc: 0.9856 - precision_26: 0.9904 - recall_26: 0.9902 - val_loss: 0.7805 - val_acc: 0.8349 - val_precision_26: 0.8615 - val_recall_26: 0.8769\n",
      "Epoch 14/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.9841 - precision_26: 0.9901 - recall_26: 0.9885Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 0.3236 - acc: 0.9839 - precision_26: 0.9899 - recall_26: 0.9884 - val_loss: 1.3663 - val_acc: 0.6843 - val_precision_26: 0.6650 - val_recall_26: 0.9974\n",
      "Epoch 15/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9891 - precision_26: 0.9935 - recall_26: 0.9919Epoch 1/20\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 0.2683 - acc: 0.9893 - precision_26: 0.9935 - recall_26: 0.9920 - val_loss: 1.1764 - val_acc: 0.7099 - val_precision_26: 0.6837 - val_recall_26: 0.9974\n",
      "Epoch 16/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.9849 - precision_26: 0.9901 - recall_26: 0.9895Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 0.2695 - acc: 0.9849 - precision_26: 0.9902 - recall_26: 0.9894 - val_loss: 1.6707 - val_acc: 0.6891 - val_precision_26: 0.6678 - val_recall_26: 1.0000\n",
      "Epoch 17/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2524 - acc: 0.9835 - precision_26: 0.9898 - recall_26: 0.9880Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 0.2519 - acc: 0.9837 - precision_26: 0.9899 - recall_26: 0.9881 - val_loss: 1.4351 - val_acc: 0.7003 - val_precision_26: 0.6771 - val_recall_26: 0.9949\n",
      "Epoch 18/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9889 - precision_26: 0.9919 - recall_26: 0.9932Epoch 1/20\n",
      "82/82 [==============================] - 54s 653ms/step - loss: 0.2255 - acc: 0.9891 - precision_26: 0.9920 - recall_26: 0.9933 - val_loss: 1.5896 - val_acc: 0.7067 - val_precision_26: 0.6813 - val_recall_26: 0.9974\n",
      "Epoch 19/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9864 - precision_26: 0.9901 - recall_26: 0.9916Epoch 1/20\n",
      "10/82 [==>...........................] - ETA: 39s - loss: 3.2300 - acc: 0.6314 - precision_26: 0.6290 - recall_26: 1.0000Restoring model weights from the end of the best epoch.\n",
      "82/82 [==============================] - 55s 667ms/step - loss: 0.2152 - acc: 0.9864 - precision_26: 0.9902 - recall_26: 0.9915 - val_loss: 3.2300 - val_acc: 0.6314 - val_precision_26: 0.6290 - val_recall_26: 1.0000\n",
      "Epoch 00019: early stopping\n",
      "Files for iteration number 13 have been exported.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 261,409\n",
      "Trainable params: 261,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 0.0017542409621782566\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None]\n",
      "Regularization_Dense_Layers[None, None]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.4180 - acc: 0.8111 - precision_28: 0.8318 - recall_28: 0.9351Epoch 1/20\n",
      "163/163 [==============================] - 58s 354ms/step - loss: 0.4180 - acc: 0.8112 - precision_28: 0.8316 - recall_28: 0.9352 - val_loss: 0.6559 - val_acc: 0.7564 - val_precision_28: 0.7429 - val_recall_28: 0.9333\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.8968 - precision_28: 0.9422 - recall_28: 0.9176Epoch 1/20\n",
      "163/163 [==============================] - 52s 322ms/step - loss: 0.2348 - acc: 0.8970 - precision_28: 0.9422 - recall_28: 0.9177 - val_loss: 1.4018 - val_acc: 0.7804 - val_precision_28: 0.7566 - val_recall_28: 0.9564\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1673 - acc: 0.9373 - precision_28: 0.9627 - recall_28: 0.9525Epoch 1/20\n",
      "163/163 [==============================] - 52s 320ms/step - loss: 0.1668 - acc: 0.9375 - precision_28: 0.9630 - recall_28: 0.9525 - val_loss: 0.8927 - val_acc: 0.7484 - val_precision_28: 0.7145 - val_recall_28: 0.9949\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9610 - precision_28: 0.9753 - recall_28: 0.9722Epoch 1/20\n",
      "163/163 [==============================] - 52s 321ms/step - loss: 0.1008 - acc: 0.9609 - precision_28: 0.9754 - recall_28: 0.9719 - val_loss: 1.8619 - val_acc: 0.7035 - val_precision_28: 0.6783 - val_recall_28: 1.0000\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9740 - precision_28: 0.9849 - recall_28: 0.9800Epoch 1/20\n",
      "163/163 [==============================] - 53s 322ms/step - loss: 0.0786 - acc: 0.9737 - precision_28: 0.9847 - recall_28: 0.9799 - val_loss: 1.1330 - val_acc: 0.8173 - val_precision_28: 0.7840 - val_recall_28: 0.9769\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9778 - precision_28: 0.9857 - recall_28: 0.9844Epoch 1/20\n",
      "163/163 [==============================] - 52s 321ms/step - loss: 0.0634 - acc: 0.9778 - precision_28: 0.9855 - recall_28: 0.9845 - val_loss: 1.9226 - val_acc: 0.7276 - val_precision_28: 0.6971 - val_recall_28: 0.9974\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9765 - precision_28: 0.9859 - recall_28: 0.9823Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 36s - loss: 1.1011 - acc: 0.8061 - precision_28: 0.7674 - recall_28: 0.9897Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 54s 332ms/step - loss: 0.0621 - acc: 0.9766 - precision_28: 0.9860 - recall_28: 0.9825 - val_loss: 1.1011 - val_acc: 0.8061 - val_precision_28: 0.7674 - val_recall_28: 0.9897\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 14 have been exported.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               663680    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 795,809\n",
      "Trainable params: 795,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 7.310343547860056e-05\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9603 - acc: 0.6311 - precision_30: 0.7419 - recall_30: 0.7720Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9602 - acc: 0.6338 - precision_30: 0.7430 - recall_30: 0.7752 - val_loss: 2.9629 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9515 - acc: 0.6961 - precision_30: 0.7440 - recall_30: 0.9001Epoch 1/20\n",
      "41/41 [==============================] - 51s 1s/step - loss: 2.9514 - acc: 0.6969 - precision_30: 0.7449 - recall_30: 0.9004 - val_loss: 2.9583 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9418 - acc: 0.7180 - precision_30: 0.7399 - recall_30: 0.9557Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9415 - acc: 0.7193 - precision_30: 0.7411 - recall_30: 0.9564 - val_loss: 2.9539 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9324 - acc: 0.7384 - precision_30: 0.7436 - recall_30: 0.9881Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9322 - acc: 0.7393 - precision_30: 0.7445 - recall_30: 0.9881 - val_loss: 2.9494 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9236 - acc: 0.7394 - precision_30: 0.7425 - recall_30: 0.9936Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9234 - acc: 0.7398 - precision_30: 0.7429 - recall_30: 0.9938 - val_loss: 2.9456 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9134 - acc: 0.7419 - precision_30: 0.7428 - recall_30: 0.9984Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9135 - acc: 0.7419 - precision_30: 0.7428 - recall_30: 0.9985 - val_loss: 2.9417 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.9046 - acc: 0.7415 - precision_30: 0.7415 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.9041 - acc: 0.7431 - precision_30: 0.7430 - recall_30: 1.0000 - val_loss: 2.9389 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8942 - acc: 0.7435 - precision_30: 0.7437 - recall_30: 0.9997Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8943 - acc: 0.7427 - precision_30: 0.7429 - recall_30: 0.9997 - val_loss: 2.9371 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8840 - acc: 0.7451 - precision_30: 0.7450 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8849 - acc: 0.7433 - precision_30: 0.7432 - recall_30: 1.0000 - val_loss: 2.9358 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8759 - acc: 0.7423 - precision_30: 0.7423 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8754 - acc: 0.7431 - precision_30: 0.7430 - recall_30: 1.0000 - val_loss: 2.9350 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8687 - acc: 0.7431 - precision_30: 0.7431 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8687 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000 - val_loss: 2.9365 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 12/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8604 - acc: 0.7427 - precision_30: 0.7429 - recall_30: 0.9997Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8603 - acc: 0.7427 - precision_30: 0.7429 - recall_30: 0.9997 - val_loss: 2.9374 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 13/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8562 - acc: 0.7433 - precision_30: 0.7433 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8562 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000 - val_loss: 2.9384 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 14/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8569 - acc: 0.7417 - precision_30: 0.7417 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8557 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000 - val_loss: 2.9416 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 15/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8481 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 2.8484 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000 - val_loss: 2.9422 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 16/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.8433 - acc: 0.7423 - precision_30: 0.7423 - recall_30: 1.0000Epoch 1/20\n",
      " 5/41 [==>...........................] - ETA: 39s - loss: 2.9447 - acc: 0.6250 - precision_30: 0.6250 - recall_30: 1.0000Restoring model weights from the end of the best epoch.\n",
      "41/41 [==============================] - 55s 1s/step - loss: 2.8429 - acc: 0.7429 - precision_30: 0.7429 - recall_30: 1.0000 - val_loss: 2.9447 - val_acc: 0.6250 - val_precision_30: 0.6250 - val_recall_30: 1.0000\n",
      "Epoch 00016: early stopping\n",
      "Files for iteration number 15 have been exported.\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 112, 112, 32)      448       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 112, 112, 32)      448       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 56, 56, 64)        224       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 28, 28, 64)        112       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 14, 14, 128)       56        \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,402,345\n",
      "Trainable params: 3,400,117\n",
      "Non-trainable params: 2,228\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 0.0002156131208142032\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.7250 - acc: 0.6260 - precision_32: 0.8475 - recall_32: 0.6051Epoch 1/20\n",
      "163/163 [==============================] - 60s 365ms/step - loss: 0.7248 - acc: 0.6260 - precision_32: 0.8480 - recall_32: 0.6049 - val_loss: 0.6900 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.7047 - precision_32: 0.9115 - recall_32: 0.6668Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 53s 323ms/step - loss: 0.6006 - acc: 0.7048 - precision_32: 0.9121 - recall_32: 0.6668 - val_loss: 0.8113 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.7533 - precision_32: 0.9459 - recall_32: 0.7083Epoch 1/20\n",
      "163/163 [==============================] - 53s 323ms/step - loss: 0.5227 - acc: 0.7535 - precision_32: 0.9459 - recall_32: 0.7086 - val_loss: 1.1197 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.4938 - acc: 0.7745 - precision_32: 0.9589 - recall_32: 0.7276Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 0.4934 - acc: 0.7749 - precision_32: 0.9592 - recall_32: 0.7280 - val_loss: 1.4282 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.7926 - precision_32: 0.9620 - recall_32: 0.7504Epoch 1/20\n",
      "163/163 [==============================] - 53s 324ms/step - loss: 0.4668 - acc: 0.7926 - precision_32: 0.9623 - recall_32: 0.7502 - val_loss: 1.6249 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.7961 - precision_32: 0.9617 - recall_32: 0.7557Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 0.4549 - acc: 0.7964 - precision_32: 0.9619 - recall_32: 0.7559 - val_loss: 1.8287 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8150 - precision_32: 0.9695 - recall_32: 0.7754Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 37s - loss: 1.7512 - acc: 0.6250 - precision_32: 0.6250 - recall_32: 1.0000Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 55s 335ms/step - loss: 0.4356 - acc: 0.8152 - precision_32: 0.9697 - recall_32: 0.7755 - val_loss: 1.7512 - val_acc: 0.6250 - val_precision_32: 0.6250 - val_recall_32: 1.0000\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 16 have been exported.\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 16)        6416      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 32)        12832     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 32)          25632     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 3, 3, 64)          51264     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 3, 3, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 243,377\n",
      "Trainable params: 242,865\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.00046479542081310116\n",
      "Momentum: 0\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.1047 - acc: 0.6640 - precision_34: 0.8234 - recall_34: 0.6977Epoch 1/20\n",
      "82/82 [==============================] - 59s 715ms/step - loss: 1.1010 - acc: 0.6666 - precision_34: 0.8250 - recall_34: 0.6996 - val_loss: 1.2230 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.7248 - acc: 0.8806 - precision_34: 0.9360 - recall_34: 0.9010Epoch 1/20\n",
      "82/82 [==============================] - 51s 625ms/step - loss: 0.7242 - acc: 0.8808 - precision_34: 0.9359 - recall_34: 0.9012 - val_loss: 1.3842 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.9125 - precision_34: 0.9457 - recall_34: 0.9360Epoch 1/20\n",
      "82/82 [==============================] - 53s 644ms/step - loss: 0.5836 - acc: 0.9126 - precision_34: 0.9458 - recall_34: 0.9360 - val_loss: 1.5506 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4842 - acc: 0.9321 - precision_34: 0.9562 - recall_34: 0.9522Epoch 1/20\n",
      "82/82 [==============================] - 52s 636ms/step - loss: 0.4845 - acc: 0.9319 - precision_34: 0.9557 - recall_34: 0.9525 - val_loss: 1.7821 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.9466 - precision_34: 0.9611 - recall_34: 0.9674Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 0.4120 - acc: 0.9467 - precision_34: 0.9610 - recall_34: 0.9675 - val_loss: 2.0531 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.9521 - precision_34: 0.9676 - recall_34: 0.9679Epoch 1/20\n",
      "82/82 [==============================] - 53s 644ms/step - loss: 0.3465 - acc: 0.9519 - precision_34: 0.9675 - recall_34: 0.9677 - val_loss: 2.4790 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.9519 - precision_34: 0.9666 - recall_34: 0.9686Epoch 1/20\n",
      "10/82 [==>...........................] - ETA: 39s - loss: 2.9122 - acc: 0.6250 - precision_34: 0.6250 - recall_34: 1.0000Restoring model weights from the end of the best epoch.\n",
      "82/82 [==============================] - 55s 668ms/step - loss: 0.3158 - acc: 0.9523 - precision_34: 0.9670 - recall_34: 0.9688 - val_loss: 2.9122 - val_acc: 0.6250 - val_precision_34: 0.6250 - val_recall_34: 1.0000\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 17 have been exported.\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      6416      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 14, 14, 64)        102464    \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,042,641\n",
      "Trainable params: 1,042,129\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 16\n",
      "Learning_Rate: 0.0008021538993948444\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.8711 - acc: 0.8285 - precision_36: 0.9744 - recall_36: 0.7898Epoch 1/20\n",
      "326/326 [==============================] - 63s 192ms/step - loss: 2.8705 - acc: 0.8286 - precision_36: 0.9745 - recall_36: 0.7899 - val_loss: 2.9686 - val_acc: 0.7308 - val_precision_36: 0.9826 - val_recall_36: 0.5795\n",
      "Epoch 2/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.6781 - acc: 0.8665 - precision_36: 0.9877 - recall_36: 0.8307Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.6782 - acc: 0.8666 - precision_36: 0.9877 - recall_36: 0.8307 - val_loss: 3.1944 - val_acc: 0.6394 - val_precision_36: 0.6341 - val_recall_36: 1.0000\n",
      "Epoch 3/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.6162 - acc: 0.8965 - precision_36: 0.9888 - recall_36: 0.8706Epoch 1/20\n",
      "326/326 [==============================] - 55s 167ms/step - loss: 2.6161 - acc: 0.8965 - precision_36: 0.9889 - recall_36: 0.8705 - val_loss: 3.2518 - val_acc: 0.6715 - val_precision_36: 0.6555 - val_recall_36: 1.0000\n",
      "Epoch 4/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.5775 - acc: 0.9071 - precision_36: 0.9865 - recall_36: 0.8871Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.5777 - acc: 0.9072 - precision_36: 0.9865 - recall_36: 0.8872 - val_loss: 2.7655 - val_acc: 0.7837 - val_precision_36: 0.7505 - val_recall_36: 0.9795\n",
      "Epoch 5/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.5257 - acc: 0.9248 - precision_36: 0.9885 - recall_36: 0.9093Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.5257 - acc: 0.9247 - precision_36: 0.9885 - recall_36: 0.9092 - val_loss: 2.7454 - val_acc: 0.7917 - val_precision_36: 0.7600 - val_recall_36: 0.9744\n",
      "Epoch 6/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4998 - acc: 0.9319 - precision_36: 0.9889 - recall_36: 0.9187Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.4998 - acc: 0.9321 - precision_36: 0.9889 - recall_36: 0.9190 - val_loss: 2.8002 - val_acc: 0.7660 - val_precision_36: 0.7346 - val_recall_36: 0.9795\n",
      "Epoch 7/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4621 - acc: 0.9417 - precision_36: 0.9877 - recall_36: 0.9332Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.4624 - acc: 0.9415 - precision_36: 0.9877 - recall_36: 0.9329 - val_loss: 2.6424 - val_acc: 0.8349 - val_precision_36: 0.8254 - val_recall_36: 0.9333\n",
      "Epoch 8/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4446 - acc: 0.9469 - precision_36: 0.9870 - recall_36: 0.9410Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.4444 - acc: 0.9471 - precision_36: 0.9870 - recall_36: 0.9412 - val_loss: 2.6712 - val_acc: 0.8189 - val_precision_36: 0.7867 - val_recall_36: 0.9744\n",
      "Epoch 9/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4214 - acc: 0.9540 - precision_36: 0.9858 - recall_36: 0.9519Epoch 1/20\n",
      "326/326 [==============================] - 55s 168ms/step - loss: 2.4222 - acc: 0.9536 - precision_36: 0.9853 - recall_36: 0.9517 - val_loss: 2.9058 - val_acc: 0.7212 - val_precision_36: 0.6935 - val_recall_36: 0.9923\n",
      "Epoch 10/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4029 - acc: 0.9523 - precision_36: 0.9868 - recall_36: 0.9485Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.4026 - acc: 0.9525 - precision_36: 0.9868 - recall_36: 0.9486 - val_loss: 3.0128 - val_acc: 0.6971 - val_precision_36: 0.6742 - val_recall_36: 0.9974\n",
      "Epoch 11/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.3784 - acc: 0.9533 - precision_36: 0.9847 - recall_36: 0.9519Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.3781 - acc: 0.9534 - precision_36: 0.9848 - recall_36: 0.9520 - val_loss: 3.0039 - val_acc: 0.7083 - val_precision_36: 0.6825 - val_recall_36: 0.9974\n",
      "Epoch 12/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.3596 - acc: 0.9596 - precision_36: 0.9854 - recall_36: 0.9599Epoch 1/20\n",
      "326/326 [==============================] - 56s 170ms/step - loss: 2.3594 - acc: 0.9597 - precision_36: 0.9854 - recall_36: 0.9600 - val_loss: 2.5849 - val_acc: 0.8429 - val_precision_36: 0.8174 - val_recall_36: 0.9641\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325/326 [============================>.] - ETA: 0s - loss: 2.3454 - acc: 0.9571 - precision_36: 0.9815 - recall_36: 0.9604Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.3452 - acc: 0.9571 - precision_36: 0.9813 - recall_36: 0.9605 - val_loss: 2.6237 - val_acc: 0.8285 - val_precision_36: 0.7979 - val_recall_36: 0.9718\n",
      "Epoch 14/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.3227 - acc: 0.9598 - precision_36: 0.9844 - recall_36: 0.9612Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.3224 - acc: 0.9599 - precision_36: 0.9844 - recall_36: 0.9613 - val_loss: 2.5314 - val_acc: 0.8654 - val_precision_36: 0.8558 - val_recall_36: 0.9436\n",
      "Epoch 15/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.3047 - acc: 0.9667 - precision_36: 0.9853 - recall_36: 0.9697Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.3047 - acc: 0.9666 - precision_36: 0.9851 - recall_36: 0.9698 - val_loss: 2.5320 - val_acc: 0.8606 - val_precision_36: 0.8499 - val_recall_36: 0.9436\n",
      "Epoch 16/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2968 - acc: 0.9638 - precision_36: 0.9847 - recall_36: 0.9664Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.2965 - acc: 0.9640 - precision_36: 0.9847 - recall_36: 0.9665 - val_loss: 2.4887 - val_acc: 0.8702 - val_precision_36: 0.8585 - val_recall_36: 0.9487\n",
      "Epoch 17/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2846 - acc: 0.9623 - precision_36: 0.9847 - recall_36: 0.9643Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.2845 - acc: 0.9622 - precision_36: 0.9845 - recall_36: 0.9644 - val_loss: 2.5446 - val_acc: 0.8494 - val_precision_36: 0.8203 - val_recall_36: 0.9718\n",
      "Epoch 18/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2603 - acc: 0.9694 - precision_36: 0.9858 - recall_36: 0.9728Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.2602 - acc: 0.9695 - precision_36: 0.9859 - recall_36: 0.9729 - val_loss: 2.6237 - val_acc: 0.7804 - val_precision_36: 0.7485 - val_recall_36: 0.9769\n",
      "Epoch 19/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2464 - acc: 0.9712 - precision_36: 0.9861 - recall_36: 0.9749Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.2462 - acc: 0.9712 - precision_36: 0.9862 - recall_36: 0.9750 - val_loss: 2.9281 - val_acc: 0.7372 - val_precision_36: 0.7062 - val_recall_36: 0.9923\n",
      "Epoch 20/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2292 - acc: 0.9712 - precision_36: 0.9866 - recall_36: 0.9744Epoch 1/20\n",
      "326/326 [==============================] - 56s 170ms/step - loss: 2.2293 - acc: 0.9711 - precision_36: 0.9864 - recall_36: 0.9745 - val_loss: 2.6734 - val_acc: 0.7772 - val_precision_36: 0.7446 - val_recall_36: 0.9795\n",
      "Files for iteration number 18 have been exported.\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 16)        6416      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 32)        12832     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               331904    \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 353,009\n",
      "Trainable params: 352,753\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 4.6753416769142944e-05\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.5385 - acc: 0.8054 - precision_38: 0.9730 - recall_38: 0.7590Epoch 1/20\n",
      "163/163 [==============================] - 58s 358ms/step - loss: 1.5373 - acc: 0.8056 - precision_38: 0.9732 - recall_38: 0.7592 - val_loss: 1.7227 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.2282 - acc: 0.8837 - precision_38: 0.9889 - recall_38: 0.8531Epoch 1/20\n",
      "163/163 [==============================] - 52s 321ms/step - loss: 1.2267 - acc: 0.8844 - precision_38: 0.9889 - recall_38: 0.8539 - val_loss: 1.8886 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.0567 - acc: 0.9095 - precision_38: 0.9896 - recall_38: 0.8875Epoch 1/20\n",
      "163/163 [==============================] - 51s 316ms/step - loss: 1.0568 - acc: 0.9095 - precision_38: 0.9896 - recall_38: 0.8875 - val_loss: 1.9648 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.9231 - acc: 0.9321 - precision_38: 0.9919 - recall_38: 0.9162Epoch 1/20\n",
      "163/163 [==============================] - 52s 321ms/step - loss: 0.9224 - acc: 0.9325 - precision_38: 0.9919 - recall_38: 0.9166 - val_loss: 2.1055 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.8305 - acc: 0.9412 - precision_38: 0.9925 - recall_38: 0.9278Epoch 1/20\n",
      "163/163 [==============================] - 52s 318ms/step - loss: 0.8301 - acc: 0.9411 - precision_38: 0.9925 - recall_38: 0.9277 - val_loss: 2.2169 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.7520 - acc: 0.9525 - precision_38: 0.9905 - recall_38: 0.9452Epoch 1/20\n",
      "163/163 [==============================] - 52s 318ms/step - loss: 0.7528 - acc: 0.9523 - precision_38: 0.9903 - recall_38: 0.9450 - val_loss: 2.4096 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 0.7075 - acc: 0.9516 - precision_38: 0.9886 - recall_38: 0.9458Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 37s - loss: 2.2707 - acc: 0.6250 - precision_38: 0.6250 - recall_38: 1.0000Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 54s 334ms/step - loss: 0.7069 - acc: 0.9517 - precision_38: 0.9884 - recall_38: 0.9461 - val_loss: 2.2707 - val_acc: 0.6250 - val_precision_38: 0.6250 - val_recall_38: 1.0000\n",
      "Epoch 00007: early stopping\n",
      "Files for iteration number 19 have been exported.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      2320      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 16)        2320      \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 16)        2320      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 32)        4640      \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "Blk5_Conv2 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 237,777\n",
      "Trainable params: 236,241\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 0.0007209011869797385\n",
      "Momentum: 0\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 3.1113 - acc: 0.8815 - precision_40: 0.9684 - recall_40: 0.8687Epoch 1/20\n",
      "41/41 [==============================] - 55s 1s/step - loss: 3.0938 - acc: 0.8832 - precision_40: 0.9687 - recall_40: 0.8710 - val_loss: 2.8790 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.9508 - acc: 0.9660 - precision_40: 0.9800 - recall_40: 0.9741Epoch 1/20\n",
      "41/41 [==============================] - 51s 1s/step - loss: 1.9418 - acc: 0.9664 - precision_40: 0.9805 - recall_40: 0.9742 - val_loss: 2.2080 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.4070 - acc: 0.9680 - precision_40: 0.9778 - recall_40: 0.9791Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.4030 - acc: 0.9676 - precision_40: 0.9776 - recall_40: 0.9788 - val_loss: 1.8467 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.0763 - acc: 0.9756 - precision_40: 0.9828 - recall_40: 0.9844Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.0730 - acc: 0.9758 - precision_40: 0.9827 - recall_40: 0.9848 - val_loss: 1.6529 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.8745 - acc: 0.9803 - precision_40: 0.9873 - recall_40: 0.9862Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.8723 - acc: 0.9806 - precision_40: 0.9876 - recall_40: 0.9863 - val_loss: 1.5425 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.7374 - acc: 0.9801 - precision_40: 0.9856 - recall_40: 0.9877Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.7355 - acc: 0.9803 - precision_40: 0.9856 - recall_40: 0.9879 - val_loss: 1.4776 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.6329 - acc: 0.9825 - precision_40: 0.9886 - recall_40: 0.9878Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.6314 - acc: 0.9827 - precision_40: 0.9886 - recall_40: 0.9881 - val_loss: 1.4501 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.5483 - acc: 0.9870 - precision_40: 0.9928 - recall_40: 0.9897Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.5483 - acc: 0.9866 - precision_40: 0.9922 - recall_40: 0.9897 - val_loss: 1.5371 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.4833 - acc: 0.9908 - precision_40: 0.9926 - recall_40: 0.9950Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.4826 - acc: 0.9908 - precision_40: 0.9925 - recall_40: 0.9951 - val_loss: 1.4897 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.4397 - acc: 0.9892 - precision_40: 0.9923 - recall_40: 0.9931Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.4400 - acc: 0.9893 - precision_40: 0.9925 - recall_40: 0.9930 - val_loss: 1.2455 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.3988 - acc: 0.9912 - precision_40: 0.9942 - recall_40: 0.9939Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.3985 - acc: 0.9910 - precision_40: 0.9941 - recall_40: 0.9938 - val_loss: 1.7143 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 12/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.3711 - acc: 0.9890 - precision_40: 0.9921 - recall_40: 0.9931Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.3714 - acc: 0.9889 - precision_40: 0.9918 - recall_40: 0.9933 - val_loss: 1.3670 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 13/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.3411 - acc: 0.9902 - precision_40: 0.9947 - recall_40: 0.9921Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.3403 - acc: 0.9904 - precision_40: 0.9948 - recall_40: 0.9923 - val_loss: 1.6526 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 14/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.3086 - acc: 0.9935 - precision_40: 0.9952 - recall_40: 0.9960Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.3082 - acc: 0.9935 - precision_40: 0.9951 - recall_40: 0.9961 - val_loss: 2.0552 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 15/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.2889 - acc: 0.9945 - precision_40: 0.9966 - recall_40: 0.9960Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 0.2884 - acc: 0.9946 - precision_40: 0.9966 - recall_40: 0.9961 - val_loss: 2.4716 - val_acc: 0.6250 - val_precision_40: 0.6250 - val_recall_40: 1.0000\n",
      "Epoch 16/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.2761 - acc: 0.9929 - precision_40: 0.9945 - recall_40: 0.9960Epoch 1/20\n",
      " 5/41 [==>...........................] - ETA: 39s - loss: 1.8868 - acc: 0.6314 - precision_40: 0.6290 - recall_40: 1.0000Restoring model weights from the end of the best epoch.\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.2758 - acc: 0.9929 - precision_40: 0.9943 - recall_40: 0.9961 - val_loss: 1.8868 - val_acc: 0.6314 - val_precision_40: 0.6290 - val_recall_40: 1.0000\n",
      "Epoch 00016: early stopping\n",
      "Files for iteration number 20 have been exported.\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      25632     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv2 (Conv2D)          (None, 75, 75, 32)        25632     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        51264     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 783,713\n",
      "Trainable params: 783,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 128\n",
      "Learning_Rate: 0.00496729393895194\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[None, None, None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 2.0862 - acc: 0.7298 - precision_42: 0.7421 - recall_42: 0.9740Epoch 1/20\n",
      "41/41 [==============================] - 60s 1s/step - loss: 2.0827 - acc: 0.7314 - precision_42: 0.7435 - recall_42: 0.9747 - val_loss: 2.0955 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 2/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.9716 - acc: 0.7441 - precision_42: 0.7441 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 50s 1s/step - loss: 1.9722 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 2.0344 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 3/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.9167 - acc: 0.7415 - precision_42: 0.7415 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.9148 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.9771 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.8647 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.8640 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.9218 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 5/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.8095 - acc: 0.7421 - precision_42: 0.7421 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.8082 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.8721 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 6/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7585 - acc: 0.7423 - precision_42: 0.7423 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.7574 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.8230 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 7/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.7142 - acc: 0.7421 - precision_42: 0.7421 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.7127 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.7771 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6653 - acc: 0.7431 - precision_42: 0.7431 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.6649 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.7321 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.6174 - acc: 0.7443 - precision_42: 0.7443 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.6182 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.6901 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.5778 - acc: 0.7431 - precision_42: 0.7431 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.5776 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.6473 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.5333 - acc: 0.7427 - precision_42: 0.7427 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.5324 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.6095 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 12/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.4746 - acc: 0.7445 - precision_42: 0.7445 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.4763 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.5699 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 13/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.4053 - acc: 0.7423 - precision_42: 0.7423 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.4037 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.5341 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 14/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.2949 - acc: 0.7435 - precision_42: 0.7435 - recall_42: 1.0000Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.2934 - acc: 0.7429 - precision_42: 0.7429 - recall_42: 1.0000 - val_loss: 1.4922 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 15/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.1897 - acc: 0.7559 - precision_42: 0.7534 - recall_42: 0.9979Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.1871 - acc: 0.7575 - precision_42: 0.7547 - recall_42: 0.9979 - val_loss: 1.4627 - val_acc: 0.6250 - val_precision_42: 0.6250 - val_recall_42: 1.0000\n",
      "Epoch 16/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.1390 - acc: 0.8445 - precision_42: 0.8629 - recall_42: 0.9399Epoch 1/20\n",
      "41/41 [==============================] - 53s 1s/step - loss: 1.1376 - acc: 0.8445 - precision_42: 0.8620 - recall_42: 0.9414 - val_loss: 1.4557 - val_acc: 0.6346 - val_precision_42: 0.6311 - val_recall_42: 1.0000\n",
      "Epoch 17/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.0785 - acc: 0.8901 - precision_42: 0.9097 - recall_42: 0.9461Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.0771 - acc: 0.8903 - precision_42: 0.9101 - recall_42: 0.9458 - val_loss: 1.4151 - val_acc: 0.6490 - val_precision_42: 0.6413 - val_recall_42: 0.9949\n",
      "Epoch 18/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.0192 - acc: 0.8988 - precision_42: 0.9225 - recall_42: 0.9428Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.0182 - acc: 0.8990 - precision_42: 0.9229 - recall_42: 0.9427 - val_loss: 1.3866 - val_acc: 0.6394 - val_precision_42: 0.6346 - val_recall_42: 0.9974\n",
      "Epoch 19/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 1.1003 - acc: 0.8351 - precision_42: 0.8872 - recall_42: 0.8912Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 1.0964 - acc: 0.8382 - precision_42: 0.8891 - recall_42: 0.8937 - val_loss: 1.4372 - val_acc: 0.3750 - val_precision_42: 0.0000e+00 - val_recall_42: 0.0000e+00\n",
      "Epoch 20/20\n",
      "40/41 [============================>.] - ETA: 1s - loss: 0.9369 - acc: 0.9180 - precision_42: 0.9441 - recall_42: 0.9459Epoch 1/20\n",
      "41/41 [==============================] - 54s 1s/step - loss: 0.9361 - acc: 0.9179 - precision_42: 0.9443 - recall_42: 0.9453 - val_loss: 1.3850 - val_acc: 0.3750 - val_precision_42: 0.0000e+00 - val_recall_42: 0.0000e+00\n",
      "Files for iteration number 21 have been exported.\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 224, 224, 16)      896       \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 56, 56, 32)        224       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 12,992,401\n",
      "Trainable params: 12,991,505\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 64\n",
      "Learning_Rate: 0.00010253355492238981\n",
      "Momentum: 0.9\n",
      "Optimization_Algo: adam\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 7.7928 - acc: 0.6995 - precision_44: 0.7909 - recall_44: 0.8087Epoch 1/20\n",
      "82/82 [==============================] - 57s 701ms/step - loss: 7.7814 - acc: 0.7015 - precision_44: 0.7925 - recall_44: 0.8103 - val_loss: 7.3196 - val_acc: 0.3750 - val_precision_44: 0.0000e+00 - val_recall_44: 0.0000e+00\n",
      "Epoch 2/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 6.4531 - acc: 0.8434 - precision_44: 0.8750 - recall_44: 0.9205Epoch 1/20\n",
      "82/82 [==============================] - 52s 637ms/step - loss: 6.4474 - acc: 0.8441 - precision_44: 0.8756 - recall_44: 0.9210 - val_loss: 6.5890 - val_acc: 0.3750 - val_precision_44: 0.0000e+00 - val_recall_44: 0.0000e+00\n",
      "Epoch 3/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 5.6852 - acc: 0.8995 - precision_44: 0.9182 - recall_44: 0.9494Epoch 1/20\n",
      "82/82 [==============================] - 53s 649ms/step - loss: 5.6825 - acc: 0.8992 - precision_44: 0.9181 - recall_44: 0.9489 - val_loss: 5.7983 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 4/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 5.0772 - acc: 0.9282 - precision_44: 0.9473 - recall_44: 0.9567Epoch 1/20\n",
      "82/82 [==============================] - 54s 655ms/step - loss: 5.0737 - acc: 0.9281 - precision_44: 0.9467 - recall_44: 0.9572 - val_loss: 5.4162 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 5/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 4.5725 - acc: 0.9352 - precision_44: 0.9538 - recall_44: 0.9593Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 4.5695 - acc: 0.9350 - precision_44: 0.9533 - recall_44: 0.9595 - val_loss: 4.8549 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 6/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 4.1398 - acc: 0.9416 - precision_44: 0.9583 - recall_44: 0.9631Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 4.1365 - acc: 0.9419 - precision_44: 0.9587 - recall_44: 0.9634 - val_loss: 4.4509 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 7/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.7633 - acc: 0.9490 - precision_44: 0.9629 - recall_44: 0.9687Epoch 1/20\n",
      "82/82 [==============================] - 53s 651ms/step - loss: 3.7631 - acc: 0.9480 - precision_44: 0.9616 - recall_44: 0.9688 - val_loss: 4.4294 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 8/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.4337 - acc: 0.9534 - precision_44: 0.9662 - recall_44: 0.9712Epoch 1/20\n",
      "82/82 [==============================] - 54s 657ms/step - loss: 3.4313 - acc: 0.9534 - precision_44: 0.9659 - recall_44: 0.9716 - val_loss: 4.6540 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 9/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 3.1519 - acc: 0.9478 - precision_44: 0.9655 - recall_44: 0.9642Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 3.1498 - acc: 0.9480 - precision_44: 0.9659 - recall_44: 0.9641 - val_loss: 4.8757 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 10/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.8894 - acc: 0.9540 - precision_44: 0.9699 - recall_44: 0.9681Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 2.8878 - acc: 0.9538 - precision_44: 0.9698 - recall_44: 0.9680 - val_loss: 5.1331 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 11/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.6425 - acc: 0.9637 - precision_44: 0.9745 - recall_44: 0.9768Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 2.6409 - acc: 0.9638 - precision_44: 0.9745 - recall_44: 0.9768 - val_loss: 5.0826 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 12/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.4510 - acc: 0.9620 - precision_44: 0.9756 - recall_44: 0.9731Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 2.4490 - acc: 0.9624 - precision_44: 0.9759 - recall_44: 0.9734 - val_loss: 4.1818 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 13/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.2572 - acc: 0.9633 - precision_44: 0.9759 - recall_44: 0.9747Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 2.2558 - acc: 0.9634 - precision_44: 0.9760 - recall_44: 0.9747 - val_loss: 4.0462 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 14/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 2.0872 - acc: 0.9660 - precision_44: 0.9775 - recall_44: 0.9767Epoch 1/20\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 2.0853 - acc: 0.9664 - precision_44: 0.9778 - recall_44: 0.9770 - val_loss: 3.9055 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 15/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.9332 - acc: 0.9705 - precision_44: 0.9804 - recall_44: 0.9799Epoch 1/20\n",
      "82/82 [==============================] - 53s 650ms/step - loss: 1.9323 - acc: 0.9707 - precision_44: 0.9804 - recall_44: 0.9801 - val_loss: 4.4783 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 16/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.7967 - acc: 0.9656 - precision_44: 0.9780 - recall_44: 0.9757Epoch 1/20\n",
      "82/82 [==============================] - 53s 646ms/step - loss: 1.7959 - acc: 0.9659 - precision_44: 0.9783 - recall_44: 0.9757 - val_loss: 4.3101 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 17/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.6824 - acc: 0.9707 - precision_44: 0.9814 - recall_44: 0.9791Epoch 1/20\n",
      "82/82 [==============================] - 53s 647ms/step - loss: 1.6808 - acc: 0.9711 - precision_44: 0.9816 - recall_44: 0.9794 - val_loss: 4.2784 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 18/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.5694 - acc: 0.9705 - precision_44: 0.9814 - recall_44: 0.9788Epoch 1/20\n",
      "82/82 [==============================] - 53s 642ms/step - loss: 1.5688 - acc: 0.9705 - precision_44: 0.9816 - recall_44: 0.9786 - val_loss: 4.0517 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 19/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.4667 - acc: 0.9720 - precision_44: 0.9804 - recall_44: 0.9820Epoch 1/20\n",
      "82/82 [==============================] - 53s 648ms/step - loss: 1.4660 - acc: 0.9720 - precision_44: 0.9804 - recall_44: 0.9819 - val_loss: 4.2594 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Epoch 20/20\n",
      "81/82 [============================>.] - ETA: 0s - loss: 1.3617 - acc: 0.9775 - precision_44: 0.9854 - recall_44: 0.9843Epoch 1/20\n",
      "82/82 [==============================] - 53s 652ms/step - loss: 1.3612 - acc: 0.9774 - precision_44: 0.9850 - recall_44: 0.9845 - val_loss: 3.8198 - val_acc: 0.6250 - val_precision_44: 0.6250 - val_recall_44: 1.0000\n",
      "Files for iteration number 22 have been exported.\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 16)      2320      \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 112, 112, 16)      2320      \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "Blk3_Conv2 (Conv2D)          (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk4_Conv2 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk5_Conv1 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Blk5_Pool1 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 492,193\n",
      "Trainable params: 491,425\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 16\n",
      "Learning_Rate: 0.005650175828840279\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[None, None, None, None, None]\n",
      "Regularization_Dense_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 3.0669 - acc: 0.7156 - precision_46: 0.8849 - recall_46: 0.7091Epoch 1/20\n",
      "326/326 [==============================] - 65s 198ms/step - loss: 3.0663 - acc: 0.7161 - precision_46: 0.8854 - recall_46: 0.7097 - val_loss: 3.0137 - val_acc: 0.6330 - val_precision_46: 0.6300 - val_recall_46: 1.0000\n",
      "Epoch 2/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.7030 - acc: 0.8760 - precision_46: 0.9442 - recall_46: 0.8853Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.7027 - acc: 0.8760 - precision_46: 0.9441 - recall_46: 0.8854 - val_loss: 3.4531 - val_acc: 0.6250 - val_precision_46: 0.6250 - val_recall_46: 1.0000\n",
      "Epoch 3/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.5458 - acc: 0.9162 - precision_46: 0.9529 - recall_46: 0.9332Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.5453 - acc: 0.9164 - precision_46: 0.9531 - recall_46: 0.9334 - val_loss: 3.7420 - val_acc: 0.6346 - val_precision_46: 0.6311 - val_recall_46: 1.0000\n",
      "Epoch 4/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.4374 - acc: 0.9229 - precision_46: 0.9510 - recall_46: 0.9449Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.4370 - acc: 0.9229 - precision_46: 0.9509 - recall_46: 0.9450 - val_loss: 4.0990 - val_acc: 0.6282 - val_precision_46: 0.6270 - val_recall_46: 1.0000\n",
      "Epoch 5/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.3299 - acc: 0.9319 - precision_46: 0.9568 - recall_46: 0.9514Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 2.3302 - acc: 0.9319 - precision_46: 0.9567 - recall_46: 0.9515 - val_loss: 2.8354 - val_acc: 0.7212 - val_precision_46: 0.6929 - val_recall_46: 0.9949\n",
      "Epoch 6/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.2256 - acc: 0.9442 - precision_46: 0.9589 - recall_46: 0.9663Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 2.2253 - acc: 0.9442 - precision_46: 0.9588 - recall_46: 0.9665 - val_loss: 3.4938 - val_acc: 0.6378 - val_precision_46: 0.6331 - val_recall_46: 1.0000\n",
      "Epoch 7/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.1561 - acc: 0.9442 - precision_46: 0.9620 - recall_46: 0.9630Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 2.1558 - acc: 0.9442 - precision_46: 0.9621 - recall_46: 0.9628 - val_loss: 2.2889 - val_acc: 0.8670 - val_precision_46: 0.8866 - val_recall_46: 0.9026\n",
      "Epoch 8/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 2.0716 - acc: 0.9458 - precision_46: 0.9597 - recall_46: 0.9676Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 2.0715 - acc: 0.9457 - precision_46: 0.9598 - recall_46: 0.9675 - val_loss: 3.8299 - val_acc: 0.6250 - val_precision_46: 0.6250 - val_recall_46: 1.0000\n",
      "Epoch 9/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.9842 - acc: 0.9548 - precision_46: 0.9690 - recall_46: 0.9702Epoch 1/20\n",
      "326/326 [==============================] - 55s 169ms/step - loss: 1.9842 - acc: 0.9546 - precision_46: 0.9688 - recall_46: 0.9701 - val_loss: 4.2749 - val_acc: 0.3846 - val_precision_46: 1.0000 - val_recall_46: 0.0154\n",
      "Epoch 10/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.9216 - acc: 0.9513 - precision_46: 0.9671 - recall_46: 0.9674Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.9212 - acc: 0.9515 - precision_46: 0.9672 - recall_46: 0.9675 - val_loss: 2.1504 - val_acc: 0.8349 - val_precision_46: 0.9208 - val_recall_46: 0.8051\n",
      "Epoch 11/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.8633 - acc: 0.9473 - precision_46: 0.9634 - recall_46: 0.9659Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 1.8632 - acc: 0.9471 - precision_46: 0.9630 - recall_46: 0.9659 - val_loss: 3.4366 - val_acc: 0.6330 - val_precision_46: 0.6300 - val_recall_46: 1.0000\n",
      "Epoch 12/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.7968 - acc: 0.9504 - precision_46: 0.9647 - recall_46: 0.9687Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.7964 - acc: 0.9505 - precision_46: 0.9648 - recall_46: 0.9688 - val_loss: 3.9423 - val_acc: 0.6250 - val_precision_46: 0.6250 - val_recall_46: 1.0000\n",
      "Epoch 13/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.7257 - acc: 0.9558 - precision_46: 0.9673 - recall_46: 0.9733Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.7254 - acc: 0.9559 - precision_46: 0.9674 - recall_46: 0.9734 - val_loss: 1.8641 - val_acc: 0.8846 - val_precision_46: 0.9015 - val_recall_46: 0.9154\n",
      "Epoch 14/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.6553 - acc: 0.9606 - precision_46: 0.9707 - recall_46: 0.9764Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.6561 - acc: 0.9603 - precision_46: 0.9705 - recall_46: 0.9763 - val_loss: 5.1337 - val_acc: 0.6250 - val_precision_46: 0.6250 - val_recall_46: 1.0000\n",
      "Epoch 15/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.6395 - acc: 0.9452 - precision_46: 0.9597 - recall_46: 0.9669Epoch 1/20\n",
      "326/326 [==============================] - 56s 171ms/step - loss: 1.6391 - acc: 0.9452 - precision_46: 0.9595 - recall_46: 0.9670 - val_loss: 1.8891 - val_acc: 0.8269 - val_precision_46: 0.9578 - val_recall_46: 0.7564\n",
      "Epoch 16/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.5743 - acc: 0.9487 - precision_46: 0.9627 - recall_46: 0.9684Epoch 1/20\n",
      "326/326 [==============================] - 56s 170ms/step - loss: 1.5743 - acc: 0.9486 - precision_46: 0.9626 - recall_46: 0.9685 - val_loss: 6.8601 - val_acc: 0.6250 - val_precision_46: 0.6250 - val_recall_46: 1.0000\n",
      "Epoch 17/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.5035 - acc: 0.9583 - precision_46: 0.9723 - recall_46: 0.9715Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.5032 - acc: 0.9584 - precision_46: 0.9724 - recall_46: 0.9716 - val_loss: 2.4683 - val_acc: 0.6827 - val_precision_46: 0.6633 - val_recall_46: 1.0000\n",
      "Epoch 18/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.4463 - acc: 0.9581 - precision_46: 0.9686 - recall_46: 0.9752Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.4460 - acc: 0.9582 - precision_46: 0.9687 - recall_46: 0.9752 - val_loss: 1.7029 - val_acc: 0.8622 - val_precision_46: 0.9294 - val_recall_46: 0.8436\n",
      "Epoch 19/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.4239 - acc: 0.9498 - precision_46: 0.9659 - recall_46: 0.9666Epoch 1/20\n",
      "326/326 [==============================] - 56s 170ms/step - loss: 1.4240 - acc: 0.9498 - precision_46: 0.9657 - recall_46: 0.9667 - val_loss: 1.7210 - val_acc: 0.7917 - val_precision_46: 0.8939 - val_recall_46: 0.7564\n",
      "Epoch 20/20\n",
      "325/326 [============================>.] - ETA: 0s - loss: 1.3605 - acc: 0.9594 - precision_46: 0.9692 - recall_46: 0.9764Epoch 1/20\n",
      "326/326 [==============================] - 55s 170ms/step - loss: 1.3601 - acc: 0.9595 - precision_46: 0.9693 - recall_46: 0.9765 - val_loss: 2.9906 - val_acc: 0.6346 - val_precision_46: 0.6311 - val_recall_46: 1.0000\n",
      "Files for iteration number 23 have been exported.\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Blk1_Conv1 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Conv2 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "Blk1_Pool1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Conv1 (Conv2D)          (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk2_Pool1 (MaxPooling2D)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Conv1 (Conv2D)          (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "Blk3_Pool1 (MaxPooling2D)    (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Conv1 (Conv2D)          (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "Blk4_Pool1 (MaxPooling2D)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 372,801\n",
      "Trainable params: 371,777\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "\n",
      "Batch_Size: 32\n",
      "Learning_Rate: 8.994343703368741e-05\n",
      "Momentum: 0\n",
      "Optimization_Algo: sgd\n",
      "Regularization_Cv_Layers[<tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d0032aef0>]\n",
      "Regularization_Dense_Layers[None]\n",
      "\n",
      "\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.7333 - acc: 0.4859 - precision_48: 0.7343 - recall_48: 0.4838Epoch 1/20\n",
      "163/163 [==============================] - 61s 375ms/step - loss: 1.7329 - acc: 0.4858 - precision_48: 0.7333 - recall_48: 0.4839 - val_loss: 2.6064 - val_acc: 0.3750 - val_precision_48: 0.0000e+00 - val_recall_48: 0.0000e+00\n",
      "Epoch 2/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.6380 - acc: 0.5386 - precision_48: 0.7792 - recall_48: 0.5287Epoch 1/20\n",
      "163/163 [==============================] - 53s 323ms/step - loss: 1.6371 - acc: 0.5391 - precision_48: 0.7798 - recall_48: 0.5290 - val_loss: 2.2124 - val_acc: 0.3750 - val_precision_48: 0.0000e+00 - val_recall_48: 0.0000e+00\n",
      "Epoch 3/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.5978 - acc: 0.5720 - precision_48: 0.8054 - recall_48: 0.5601Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 1.5975 - acc: 0.5729 - precision_48: 0.8049 - recall_48: 0.5610 - val_loss: 1.8190 - val_acc: 0.3750 - val_precision_48: 0.0000e+00 - val_recall_48: 0.0000e+00\n",
      "Epoch 4/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.5702 - acc: 0.5997 - precision_48: 0.8290 - recall_48: 0.5807Epoch 1/20\n",
      "163/163 [==============================] - 53s 324ms/step - loss: 1.5700 - acc: 0.5995 - precision_48: 0.8293 - recall_48: 0.5804 - val_loss: 1.6475 - val_acc: 0.3750 - val_precision_48: 0.0000e+00 - val_recall_48: 0.0000e+00\n",
      "Epoch 5/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.5305 - acc: 0.6327 - precision_48: 0.8545 - recall_48: 0.6089Epoch 1/20\n",
      "163/163 [==============================] - 53s 326ms/step - loss: 1.5305 - acc: 0.6329 - precision_48: 0.8551 - recall_48: 0.6090 - val_loss: 1.5734 - val_acc: 0.4167 - val_precision_48: 1.0000 - val_recall_48: 0.0667\n",
      "Epoch 6/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.5149 - acc: 0.6532 - precision_48: 0.8713 - recall_48: 0.6257Epoch 1/20\n",
      "163/163 [==============================] - 53s 322ms/step - loss: 1.5158 - acc: 0.6522 - precision_48: 0.8703 - recall_48: 0.6250 - val_loss: 1.5457 - val_acc: 0.6266 - val_precision_48: 0.6260 - val_recall_48: 1.0000\n",
      "Epoch 7/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4960 - acc: 0.6680 - precision_48: 0.8831 - recall_48: 0.6375Epoch 1/20\n",
      "163/163 [==============================] - 53s 323ms/step - loss: 1.4964 - acc: 0.6679 - precision_48: 0.8831 - recall_48: 0.6374 - val_loss: 1.5465 - val_acc: 0.6266 - val_precision_48: 0.6260 - val_recall_48: 1.0000\n",
      "Epoch 8/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4840 - acc: 0.6734 - precision_48: 0.8846 - recall_48: 0.6439Epoch 1/20\n",
      "163/163 [==============================] - 53s 324ms/step - loss: 1.4849 - acc: 0.6722 - precision_48: 0.8845 - recall_48: 0.6426 - val_loss: 1.5377 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 9/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4693 - acc: 0.6927 - precision_48: 0.8964 - recall_48: 0.6629Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 1.4687 - acc: 0.6936 - precision_48: 0.8971 - recall_48: 0.6637 - val_loss: 1.5432 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 10/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4535 - acc: 0.7004 - precision_48: 0.9042 - recall_48: 0.6671Epoch 1/20\n",
      "163/163 [==============================] - 53s 323ms/step - loss: 1.4535 - acc: 0.7000 - precision_48: 0.9044 - recall_48: 0.6666 - val_loss: 1.5369 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 11/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4522 - acc: 0.6985 - precision_48: 0.8999 - recall_48: 0.6681Epoch 1/20\n",
      "163/163 [==============================] - 53s 327ms/step - loss: 1.4522 - acc: 0.6984 - precision_48: 0.9005 - recall_48: 0.6679 - val_loss: 1.5311 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 12/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4360 - acc: 0.7164 - precision_48: 0.9157 - recall_48: 0.6815Epoch 1/20\n",
      "163/163 [==============================] - 53s 326ms/step - loss: 1.4354 - acc: 0.7170 - precision_48: 0.9158 - recall_48: 0.6818 - val_loss: 1.5337 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 13/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4362 - acc: 0.7176 - precision_48: 0.9114 - recall_48: 0.6865Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 1.4363 - acc: 0.7172 - precision_48: 0.9115 - recall_48: 0.6859 - val_loss: 1.5341 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 14/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4210 - acc: 0.7323 - precision_48: 0.9217 - recall_48: 0.6992Epoch 1/20\n",
      "163/163 [==============================] - 53s 325ms/step - loss: 1.4208 - acc: 0.7322 - precision_48: 0.9214 - recall_48: 0.6991 - val_loss: 1.5341 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 15/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4157 - acc: 0.7409 - precision_48: 0.9225 - recall_48: 0.7110Epoch 1/20\n",
      "163/163 [==============================] - 53s 323ms/step - loss: 1.4155 - acc: 0.7406 - precision_48: 0.9226 - recall_48: 0.7105 - val_loss: 1.5316 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 16/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4001 - acc: 0.7427 - precision_48: 0.9256 - recall_48: 0.7107Epoch 1/20\n",
      "163/163 [==============================] - 53s 324ms/step - loss: 1.4004 - acc: 0.7423 - precision_48: 0.9254 - recall_48: 0.7105 - val_loss: 1.5319 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 17/20\n",
      "162/163 [============================>.] - ETA: 0s - loss: 1.4033 - acc: 0.7492 - precision_48: 0.9259 - recall_48: 0.7201Epoch 1/20\n",
      " 20/163 [==>...........................] - ETA: 37s - loss: 1.5324 - acc: 0.6250 - precision_48: 0.6250 - recall_48: 1.0000Restoring model weights from the end of the best epoch.\n",
      "163/163 [==============================] - 56s 341ms/step - loss: 1.4045 - acc: 0.7487 - precision_48: 0.9253 - recall_48: 0.7197 - val_loss: 1.5324 - val_acc: 0.6250 - val_precision_48: 0.6250 - val_recall_48: 1.0000\n",
      "Epoch 00017: early stopping\n",
      "Files for iteration number 24 have been exported.\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    \n",
    "    hyperparams = set_hyperparameters(param_values)\n",
    "    Model = generate_model(hyperparams)\n",
    "    \n",
    "    Model.summary()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Batch_Size: \"+str(hyperparams['BS']))\n",
    "    print(\"Learning_Rate: \"+str(hyperparams['LR']))\n",
    "    print(\"Momentum: \"+str(hyperparams['Mtm']))\n",
    "    print(\"Optimization_Algo: \"+str(hyperparams['Opt_Algo']))\n",
    "    print(\"Regularization_Cv_Layers\" + str(hyperparams['Cv_Reg']))\n",
    "    print(\"Regularization_Dense_Layers\" + str(hyperparams['Dl_Reg']))\n",
    "    print ()\n",
    "    print(\"\")\n",
    "\n",
    "    train_gen, test_gen = prepare_train_test_data(train_dir, test_dir, \n",
    "                                                      hyperparams['BS'], Input_Shape_WO_Channel)\n",
    "    compile_and_run_model(Model, hyperparams['Opt_Algo'], hyperparams['LR'], hyperparams['Mtm'],\n",
    "                              Loss, Metrics)\n",
    "    callbacks = prepare_callbacks(6)\n",
    "    \n",
    "    history = Model.fit(train_gen, validation_data= test_gen,\n",
    "                            epochs = 30, verbose=1, callbacks = callbacks)\n",
    "    \n",
    "    File_Name1 = 'Hyperparams_Model_' + str(i) + '.txt'\n",
    "    File_Name2 = 'Model_Results_' + str(i) + '.csv'\n",
    "    \n",
    "    export_results(i, history, hyperparams, File_Name1, File_Name2)\n",
    "    del(Model, history, train_gen, test_gen, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
